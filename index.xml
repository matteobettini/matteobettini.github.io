<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Matteo Bettini</title><link>https://matteobettini.github.io/</link><atom:link href="https://matteobettini.github.io/index.xml" rel="self" type="application/rss+xml"/><description>Matteo Bettini</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate><image><url>https://matteobettini.github.io/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_512x512_fill_lanczos_center_3.png</url><title>Matteo Bettini</title><link>https://matteobettini.github.io/</link></image><item><title>Python basics</title><link>https://matteobettini.github.io/courses/example/python/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/courses/example/python/</guid><description>&lt;p>Build a foundation in Python.&lt;/p>
&lt;p>
&lt;i class="fas fa-clock pr-1 fa-fw">&lt;/i> 1-2 hours per week, for 8 weeks&lt;/p>
&lt;h2 id="learn">Learn&lt;/h2>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/rfscVS0vtbw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="quiz">Quiz&lt;/h2>
&lt;details class="spoiler " id="spoiler-2">
&lt;summary>What is the difference between lists and tuples?&lt;/summary>
&lt;p>&lt;p>Lists&lt;/p>
&lt;ul>
&lt;li>Lists are mutable - they can be changed&lt;/li>
&lt;li>Slower than tuples&lt;/li>
&lt;li>Syntax: &lt;code>a_list = [1, 2.0, 'Hello world']&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>Tuples&lt;/p>
&lt;ul>
&lt;li>Tuples are immutable - they can&amp;rsquo;t be changed&lt;/li>
&lt;li>Tuples are faster than lists&lt;/li>
&lt;li>Syntax: &lt;code>a_tuple = (1, 2.0, 'Hello world')&lt;/code>&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-3">
&lt;summary>Is Python case-sensitive?&lt;/summary>
&lt;p>Yes&lt;/p>
&lt;/details></description></item><item><title>Visualization</title><link>https://matteobettini.github.io/courses/example/visualization/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/courses/example/visualization/</guid><description>&lt;p>Learn how to visualize data with Plotly.&lt;/p>
&lt;p>
&lt;i class="fas fa-clock pr-1 fa-fw">&lt;/i> 1-2 hours per week, for 8 weeks&lt;/p>
&lt;h2 id="learn">Learn&lt;/h2>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/hSPmj7mK6ng" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="quiz">Quiz&lt;/h2>
&lt;details class="spoiler " id="spoiler-2">
&lt;summary>When is a heatmap useful?&lt;/summary>
&lt;p>Lorem ipsum dolor sit amet, consectetur adipiscing elit.&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-3">
&lt;summary>Write Plotly code to render a bar chart&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-python">import plotly.express as px
data_canada = px.data.gapminder().query(&amp;quot;country == 'Canada'&amp;quot;)
fig = px.bar(data_canada, x='year', y='pop')
fig.show()
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details></description></item><item><title>Statistics</title><link>https://matteobettini.github.io/courses/example/stats/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/courses/example/stats/</guid><description>&lt;p>Introduction to statistics for data science.&lt;/p>
&lt;p>
&lt;i class="fas fa-clock pr-1 fa-fw">&lt;/i> 1-2 hours per week, for 8 weeks&lt;/p>
&lt;h2 id="learn">Learn&lt;/h2>
&lt;p>The general form of the &lt;strong>normal&lt;/strong> probability density function is:&lt;/p>
&lt;p>$$
f(x) = \frac{1}{\sigma \sqrt{2\pi} } e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}
$$&lt;/p>
&lt;div class="alert alert-note">
&lt;div>
The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
&lt;/div>
&lt;/div>
&lt;h2 id="quiz">Quiz&lt;/h2>
&lt;details class="spoiler " id="spoiler-2">
&lt;summary>What is the parameter $\mu$?&lt;/summary>
&lt;p>The parameter $\mu$ is the mean or expectation of the distribution.&lt;/p>
&lt;/details></description></item><item><title>Example Talk</title><link>https://matteobettini.github.io/talk/example-talk/</link><pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate><guid>https://matteobettini.github.io/talk/example-talk/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click on the &lt;strong>Slides&lt;/strong> button above to view the built-in slides feature.
&lt;/div>
&lt;/div>
&lt;p>Slides can be added in a few ways:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Create&lt;/strong> slides using Wowchemy&amp;rsquo;s &lt;a href="https://wowchemy.com/docs/managing-content/#create-slides" target="_blank" rel="noopener">&lt;em>Slides&lt;/em>&lt;/a> feature and link using &lt;code>slides&lt;/code> parameter in the front matter of the talk file&lt;/li>
&lt;li>&lt;strong>Upload&lt;/strong> an existing slide deck to &lt;code>static/&lt;/code> and link using &lt;code>url_slides&lt;/code> parameter in the front matter of the talk file&lt;/li>
&lt;li>&lt;strong>Embed&lt;/strong> your slides (e.g. Google Slides) or presentation video on this page using &lt;a href="https://wowchemy.com/docs/writing-markdown-latex/" target="_blank" rel="noopener">shortcodes&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>Further event details, including &lt;a href="https://wowchemy.com/docs/writing-markdown-latex/" target="_blank" rel="noopener">page elements&lt;/a> such as image galleries, can be added to the body of this page.&lt;/p></description></item><item><title>BenchMARL: Benchmarking Multi-Agent Reinforcement Learning</title><link>https://matteobettini.github.io/publication/benchmarl/</link><pubDate>Mon, 04 Dec 2023 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/publication/benchmarl/</guid><description/></item><item><title>TorchRL: A data-driven decision-making library for PyTorch</title><link>https://matteobettini.github.io/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/</guid><description/></item><item><title>System Neural Diversity: Measuring Behavioral Heterogeneity in Multi-Agent Learning</title><link>https://matteobettini.github.io/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/</link><pubDate>Sat, 01 Apr 2023 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/</guid><description/></item><item><title>Heterogeneous Multi-Robot Reinforcement Learning</title><link>https://matteobettini.github.io/publication/heterogeneous-multi-robot-reinforcement-learning/</link><pubDate>Thu, 05 Jan 2023 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/publication/heterogeneous-multi-robot-reinforcement-learning/</guid><description/></item><item><title>POPGym: Benchmarking Partially Observable Reinforcement Learning</title><link>https://matteobettini.github.io/publication/popgym-benchmarking-partially-observable-reinforcement-learning/</link><pubDate>Wed, 04 Jan 2023 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/publication/popgym-benchmarking-partially-observable-reinforcement-learning/</guid><description/></item><item><title>VMAS: A Vectorized Multi-Agent Simulator for Collective Robot Learning</title><link>https://matteobettini.github.io/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/</link><pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/</guid><description>&lt;h1 id="scenarios">Scenarios&lt;/h1>
&lt;figure id="figure-multi-robot-scenarios-introduced-in-vmas-robots-blue-shapes-interact-among-each-other-and-with-landmarks-green-red-and-black-shapes-to-solve-a-task">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Multi-robot scenarios introduced in VMAS. Robots (blue shapes) interact among each other and with landmarks (green, red, and black shapes) to solve a task."
src="https://matteobettini.github.io/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/VMAS_scenarios.gif"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Multi-robot scenarios introduced in VMAS. Robots (blue shapes) interact among each other and with landmarks (green, red, and black shapes) to solve a task.
&lt;/figcaption>&lt;/figure>
&lt;h1 id="video">Video&lt;/h1>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/aaDRYfiesAY" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>On the Properties of Path Additions for Traffic Routing</title><link>https://matteobettini.github.io/publication/on-the-properties-of-path-additions-for-traffic-routing/</link><pubDate>Sun, 06 Feb 2022 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/publication/on-the-properties-of-path-additions-for-traffic-routing/</guid><description/></item><item><title>BenchMARL - Benchmarking Multi-Agent Reinforcement Learning</title><link>https://matteobettini.github.io/post/benchmarl/</link><pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/post/benchmarl/</guid><description>&lt;!-- ![BenchMARL](https://github.com/matteobettini/vmas-media/blob/main/media/benchmarl.png?raw=true) -->
&lt;p>&lt;strong>TL;DR:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>We introduce BenchMARL, a training library for benchmarking MARL algorithms, tasks, and models backed by TorchRL.&lt;/li>
&lt;li>BenchMARL already contains a variety of SOTA algorithms and tasks.&lt;/li>
&lt;li>BenchMARL is grounded by its core tenets: standardization and reproducibility&lt;/li>
&lt;/ul>
&lt;h1 id="what-is-benchmarl-">What is BenchMARL 🧐?&lt;/h1>
&lt;p>BenchMARL is a Multi-Agent Reinforcement Learning (MARL) training library created to enable reproducibility
and benchmarking across different MARL algorithms and environments.
Its mission is to present a standardized interface that allows easy integration of new algorithms and environments to
provide a fair comparison with existing solutions.
BenchMARL uses &lt;a href="https://github.com/pytorch/rl" target="_blank" rel="noopener">TorchRL&lt;/a> as its backend, which grants it high performance
and state-of-the-art implementations.
It also uses &lt;a href="https://hydra.cc/docs/intro/" target="_blank" rel="noopener">hydra&lt;/a> for flexible and modular configuration,
and its data reporting is compatible with &lt;a href="https://sites.google.com/view/marl-standard-protocol/home" target="_blank" rel="noopener">marl-eval&lt;/a>
for standardised and statistically strong evaluations.&lt;/p>
&lt;p>BenchMARL &lt;strong>core design tenets&lt;/strong> are:&lt;/p>
&lt;ul>
&lt;li>&lt;em>Reproducibility through systematical grounding and standardization of configuration&lt;/em>&lt;/li>
&lt;li>&lt;em>Standardised and statistically-strong plotting and reporting&lt;/em>&lt;/li>
&lt;li>&lt;em>Experiments that are independent of the algorithm, environment, and model choices&lt;/em>&lt;/li>
&lt;li>&lt;em>Breadth over the MARL ecosystem&lt;/em>&lt;/li>
&lt;li>&lt;em>Easy implementation of new algorithms, environments, and models&lt;/em>&lt;/li>
&lt;li>&lt;em>Leveraging the know-how and infrastructure of &lt;a href="https://github.com/pytorch/rl" target="_blank" rel="noopener">TorchRL&lt;/a>, without reinventing the wheel&lt;/em>&lt;/li>
&lt;/ul>
&lt;h1 id="why-would-i-benchmarl-">Why would I BenchMARL 🤔?&lt;/h1>
&lt;p>Why would you BenchMARL, I see you ask.
Well, you can BenchMARL to compare different algorithms, environments, models,
to check how your new research compares to existing ones, or if you just want to approach
the domain and want to easily take a picture of the landscape.&lt;/p>
&lt;h1 id="why-does-it-exist">Why does it exist?&lt;/h1>
&lt;p>We created it because, compared to other ML domains, RL has always been more fragmented
in terms of shared community standards, tools, and interfaces.
In MARL, this problem is even more evident, with new libraries being frequently
introduced that focus on specific algorithms, environments, or models. Furthermore,
these libraries often implement components from scratch, without leveraging the know-how of
the single-agent RL community. In fact, the great majority of components used in MARL is shared
with single-agent RL (e.g., losses like MAPPO, models, probability distributions, replay buffers, and much more).&lt;/p>
&lt;p>This fragmentation of the domain has led to a reproducibility crisis, recently highlighted in
a NeurIPS paper &lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. While authors in &lt;sup id="fnref1:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> propose a set of tools for statistically-strong results&amp;rsquo; reporting,
there is still the need for a standardized library to run such benchmarks.
This is where BenchMARL comes in. Its mission is to provide a benchmarking tool for MARL,
leveraging the components of TorchRL for a solid RL backend.&lt;/p>
&lt;h1 id="how-do-i-use-it">How do I use it?&lt;/h1>
&lt;h3 id="command-line">Command line&lt;/h3>
&lt;p>Simple, to run an experiment from the command line do:&lt;/p>
&lt;pre>&lt;code class="language-bash">python benchmarl/run.py algorithm=mappo task=vmas/balance
&lt;/code>&lt;/pre>
&lt;p>to run multiple experiments, a benchmark you can do:&lt;/p>
&lt;pre>&lt;code class="language-bash">python benchmarl/run.py -m algorithm=mappo,qmix,masac task=vmas/balance,vmas/sampling seed=0,1
&lt;/code>&lt;/pre>
&lt;p>Multirun has many launchers supported in the backend.
The default implementation for hydra multirun is sequential, but &lt;a href="https://hydra.cc/docs/plugins/joblib_launcher/" target="_blank" rel="noopener">parallel&lt;/a> and
&lt;a href="https://hydra.cc/docs/plugins/submitit_launcher/" target="_blank" rel="noopener">slurm&lt;/a> launchers are also available.&lt;/p>
&lt;h3 id="script">Script&lt;/h3>
&lt;p>Run an experiment:&lt;/p>
&lt;pre>&lt;code class="language-python">experiment = Experiment(
task=VmasTask.BALANCE.get_from_yaml(),
algorithm_config=MappoConfig.get_from_yaml(),
model_config=MlpConfig.get_from_yaml(),
critic_model_config=MlpConfig.get_from_yaml(),
seed=0,
config=ExperimentConfig.get_from_yaml(),
)
experiment.run()
&lt;/code>&lt;/pre>
&lt;p>Run a benchmark:&lt;/p>
&lt;pre>&lt;code class="language-python">benchmark = Benchmark(
algorithm_configs=[
MappoConfig.get_from_yaml(),
QmixConfig.get_from_yaml(),
MasacConfig.get_from_yaml(),
],
tasks=[
VmasTask.BALANCE.get_from_yaml(),
VmasTask.SAMPLING.get_from_yaml(),
],
seeds={0, 1},
experiment_config=ExperimentConfig.get_from_yaml(),
model_config=MlpConfig.get_from_yaml(),
critic_model_config=MlpConfig.get_from_yaml(),
)
benchmark.run_sequential()
&lt;/code>&lt;/pre>
&lt;h1 id="components">Components&lt;/h1>
&lt;p>The goal of BenchMARL is to bring different MARL environments and algorithms
under the same interfaces to enable fair and reproducible comparison and benchmarking.
BenchMARL is a full-pipline unified training library with the goal of enabling users to run
any comparison they want across our algorithms and tasks in just one line of code.
To achieve this, BenchMARL interconnects components from &lt;a href="https://github.com/pytorch/rl" target="_blank" rel="noopener">TorchRL&lt;/a>,
which provides an efficient and reliable backend.&lt;/p>
&lt;p>The library has a &lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf" target="_blank" rel="noopener">default configuration&lt;/a> for each of its components.
While parts of this configuration are supposed to be changed (for example experiment configurations),
other parts (such as tasks) should not be changed to allow for reproducibility.
To aid in this, each version of BenchMARL is paired to a default configuration.&lt;/p>
&lt;p>Let&amp;rsquo;s now introduce each component in the library.&lt;/p>
&lt;p>&lt;strong>Experiment&lt;/strong>. An experiment is a training run in which an algorithm, a task, and a model are fixed.
Experiments are configured by passing these values alongside a seed and the experiment hyperparameters.
The experiment &lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf/experiment/base_experiment.yaml" target="_blank" rel="noopener">hyperparameters&lt;/a> cover both
on-policy and off-policy algorithms, discrete and continuous actions, and probabilistic and deterministic policies
(as they are agnostic of the algorithm or task used).
An experiment can be launched from the command line or from a script.&lt;/p>
&lt;p>&lt;strong>Benchmark&lt;/strong>. In the library we call &lt;code>benchmark&lt;/code> a collection of experiments that can vary in tasks, algorithm, or model.
A benchmark shares the same experiment configuration across all of its experiments.
Benchmarks allow to compare different MARL components in a standardized way.
A benchmark can be launched from the command line or from a script.&lt;/p>
&lt;p>&lt;strong>Algorithms&lt;/strong>. Algorithms are an ensemble of components (e.g., losss, replay buffer) which
determine the training strategy. Here is a table with the currently implemented algorithms in BenchMARL.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Name&lt;/th>
&lt;th>On/Off policy&lt;/th>
&lt;th>Actor-critic&lt;/th>
&lt;th>Full-observability in critic&lt;/th>
&lt;th>Action compatibility&lt;/th>
&lt;th>Probabilistic actor&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;a href="https://arxiv.org/abs/2103.01955" target="_blank" rel="noopener">MAPPO&lt;/a>&lt;/td>
&lt;td>On&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Continuous + Discrete&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;a href="https://arxiv.org/abs/2011.09533" target="_blank" rel="noopener">IPPO&lt;/a>&lt;/td>
&lt;td>On&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Continuous + Discrete&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;a href="https://arxiv.org/abs/1706.02275" target="_blank" rel="noopener">MADDPG&lt;/a>&lt;/td>
&lt;td>Off&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Continuous&lt;/td>
&lt;td>No&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/algorithms/iddpg.py" target="_blank" rel="noopener">IDDPG&lt;/a>&lt;/td>
&lt;td>Off&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Continuous&lt;/td>
&lt;td>No&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/algorithms/masac.py" target="_blank" rel="noopener">MASAC&lt;/a>&lt;/td>
&lt;td>Off&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Continuous + Discrete&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/algorithms/isac.py" target="_blank" rel="noopener">ISAC&lt;/a>&lt;/td>
&lt;td>Off&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Continuous + Discrete&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;a href="https://arxiv.org/abs/1803.11485" target="_blank" rel="noopener">QMIX&lt;/a>&lt;/td>
&lt;td>Off&lt;/td>
&lt;td>No&lt;/td>
&lt;td>NA&lt;/td>
&lt;td>Discrete&lt;/td>
&lt;td>No&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;a href="https://arxiv.org/abs/1706.05296" target="_blank" rel="noopener">VDN&lt;/a>&lt;/td>
&lt;td>Off&lt;/td>
&lt;td>No&lt;/td>
&lt;td>NA&lt;/td>
&lt;td>Discrete&lt;/td>
&lt;td>No&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;a href="https://www.semanticscholar.org/paper/Multi-Agent-Reinforcement-Learning%3A-Independent-Tan/59de874c1e547399b695337bcff23070664fa66e" target="_blank" rel="noopener">IQL&lt;/a>&lt;/td>
&lt;td>Off&lt;/td>
&lt;td>No&lt;/td>
&lt;td>NA&lt;/td>
&lt;td>Discrete&lt;/td>
&lt;td>No&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Tasks&lt;/strong>. Tasks are scenarios from a specific environment which constitute the MARL
challenge to solve.
They differ based on many aspects, here is a table with the current environments in BenchMARL&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Environment&lt;/th>
&lt;th>Tasks&lt;/th>
&lt;th>Cooperation&lt;/th>
&lt;th>Global state&lt;/th>
&lt;th>Reward function&lt;/th>
&lt;th>Action space&lt;/th>
&lt;th style="text-align:center">Vectorized&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;a href="https://github.com/proroklab/VectorizedMultiAgentSimulator" target="_blank" rel="noopener">VMAS&lt;/a>&lt;/td>
&lt;td>&lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf/task/vmas" target="_blank" rel="noopener">5&lt;/a>&lt;/td>
&lt;td>Cooperative + Competitive&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Shared + Independent + Global&lt;/td>
&lt;td>Continuous + Discrete&lt;/td>
&lt;td style="text-align:center">Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;a href="https://github.com/oxwhirl/smacv2" target="_blank" rel="noopener">SMACv2&lt;/a>&lt;/td>
&lt;td>&lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf/task/smacv2" target="_blank" rel="noopener">15&lt;/a>&lt;/td>
&lt;td>Cooperative&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Global&lt;/td>
&lt;td>Discrete&lt;/td>
&lt;td style="text-align:center">No&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;a href="https://github.com/openai/multiagent-particle-envs" target="_blank" rel="noopener">MPE&lt;/a>&lt;/td>
&lt;td>&lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf/task/pettingzoo" target="_blank" rel="noopener">8&lt;/a>&lt;/td>
&lt;td>Cooperative + Competitive&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Shared + Independent&lt;/td>
&lt;td>Continuous + Discrete&lt;/td>
&lt;td style="text-align:center">No&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;a href="https://github.com/sisl/MADRL" target="_blank" rel="noopener">SISL&lt;/a>&lt;/td>
&lt;td>&lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf/task/pettingzoo" target="_blank" rel="noopener">2&lt;/a>&lt;/td>
&lt;td>Cooperative&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Shared&lt;/td>
&lt;td>Continuous&lt;/td>
&lt;td style="text-align:center">No&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;blockquote>
&lt;p>BenchMARL uses the &lt;a href="https://github.com/pytorch/rl/issues/1463" target="_blank" rel="noopener">TorchRL MARL API&lt;/a> for grouping agents.
In competitive environments like MPE, for example, teams will be in different groups. Each group has its own loss,
models, buffers, and so on. Parameter sharing options refer to sharing within the group. See the example on &lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/examples/extending/algorithm/custom_algorithm.py" target="_blank" rel="noopener">creating
a custom algorithm&lt;/a> for more info.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>Models&lt;/strong>. Models are neural networks used to process data. They can be used as actors (policies) or,
when requested, as critics. We provide a set of base models (layers) and a SequenceModel to concatenate
different layers. All the models can be used with or without parameter sharing within an
agent group. Here is a table of the models implemented in BenchMARL&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Name&lt;/th>
&lt;th style="text-align:center">Decentralized&lt;/th>
&lt;th style="text-align:center">Centralized with local inputs&lt;/th>
&lt;th style="text-align:center">Centralized with global input&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/models/mlp.py" target="_blank" rel="noopener">MLP&lt;/a>&lt;/td>
&lt;td style="text-align:center">Yes&lt;/td>
&lt;td style="text-align:center">Yes&lt;/td>
&lt;td style="text-align:center">Yes&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>And the ones that are &lt;em>work in progress&lt;/em>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Name&lt;/th>
&lt;th style="text-align:center">Decentralized&lt;/th>
&lt;th style="text-align:center">Centralized with local inputs&lt;/th>
&lt;th style="text-align:center">Centralized with global input&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>GNN&lt;/td>
&lt;td style="text-align:center">Yes&lt;/td>
&lt;td style="text-align:center">Yes&lt;/td>
&lt;td style="text-align:center">No&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>CNN&lt;/td>
&lt;td style="text-align:center">Yes&lt;/td>
&lt;td style="text-align:center">Yes&lt;/td>
&lt;td style="text-align:center">Yes&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="features">Features&lt;/h1>
&lt;p>BenchMARL has many features. In this section we will dive deep
in the features that correspond to our core design tenets, but there are many more cool
nuggets here and there, such as:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>A test CI&lt;/strong> with integration and training test routines that are run &lt;strong>for all simulators and algorithms&lt;/strong>&lt;/li>
&lt;li>Integration in the &lt;strong>official TorchRL ecosystem&lt;/strong> for dedicated support&lt;/li>
&lt;li>Experiment &lt;strong>checkpointing&lt;/strong> and restoring using &lt;code>torch&lt;/code>&lt;/li>
&lt;li>Experiment &lt;strong>logging&lt;/strong> compatible with many loggers (wandb, csv, mflow, tensorboard).
The wandb logger is fully compatible with experiment restoring and will automatically resume the run of the loaded experiment.&lt;/li>
&lt;/ul>
&lt;p>In the following we illustrate the features which are core to our tenets.&lt;/p>
&lt;h2 id="fine-tuned-public-benchmarks">Fine-tuned public benchmarks&lt;/h2>
&lt;p>In the &lt;a href="https://github.com/facebookresearch/BenchMARL/blob/main/fine_tuned" target="_blank" rel="noopener">fine_tuned&lt;/a> folder
we are collecting some tested hyperparameters for
specific environments to enable users to bootstrap their benchmarking.
You can just run the scripts in this folder to automatically use the proposed hyperparameters.&lt;/p>
&lt;p>We will tune benchmarks for you and publish the config and benchmarking plots on
&lt;a href="https://wandb.ai/matteobettini/benchmarl-public/reportlist" target="_blank" rel="noopener">Wandb&lt;/a> publicly&lt;/p>
&lt;p>Currently available ones are:&lt;/p>
&lt;div class="row">
&lt;b>VVMAS:&lt;/b>
&lt;a href="https://github.com/facebookresearch/BenchMARL/blob/main/fine_tuned/vmas/conf/config.yaml">
&lt;img src=https://img.shields.io/badge/Conf-purple.svg />
&lt;/a>
&lt;a href="https://api.wandb.ai/links/matteobettini/r5744vas">
&lt;img src=https://img.shields.io/badge/Benchmarks-Wandb-yellow />
&lt;/a>&lt;/div>
&lt;p>In the following, we report a table of the results:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>&lt;p align="center">Environment&lt;/p>&lt;/strong>&lt;/th>
&lt;th>&lt;strong>&lt;p align="center">Sample efficiency curves (all tasks)&lt;/p>&lt;/strong>&lt;/th>
&lt;th>&lt;strong>&lt;p align="center">Performance profile&lt;/p>&lt;/strong>&lt;/th>
&lt;th>&lt;strong>&lt;p align="center">Aggregate scores&lt;/p>&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>VMAS&lt;/td>
&lt;td>&lt;img src="https://raw.githubusercontent.com/matteobettini/benchmarl_sphinx_theme/master/benchmarl_sphinx_theme/static/img/benchmarks/vmas/environemnt_sample_efficiency_curves.png"/>&lt;/td>
&lt;td>&lt;img src="https://raw.githubusercontent.com/matteobettini/benchmarl_sphinx_theme/master/benchmarl_sphinx_theme/static/img/benchmarks/vmas/performance_profile_figure.png"/>&lt;/td>
&lt;td>&lt;img src="https://raw.githubusercontent.com/matteobettini/benchmarl_sphinx_theme/master/benchmarl_sphinx_theme/static/img/benchmarks/vmas/aggregate_scores.png"/>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="reporting-and-plotting">Reporting and plotting&lt;/h2>
&lt;p>Reporting and plotting is compatible with &lt;a href="https://github.com/instadeepai/marl-eval" target="_blank" rel="noopener">marl-eval&lt;/a>.
If &lt;code>experiment.create_json=True&lt;/code> (this is the default in the &lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf/experiment/base_experiment.yaml" target="_blank" rel="noopener">experiment config&lt;/a>)
a file named &lt;code>{experiment_name}.json&lt;/code> will be created in the experiment output folder with the format of &lt;a href="https://github.com/instadeepai/marl-eval" target="_blank" rel="noopener">marl-eval&lt;/a>.
You can load and merge these files using the utils in &lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/eval_results.py" target="_blank" rel="noopener">eval_results&lt;/a> to create beautiful plots of
your benchmarks. No more struggling with matplotlib and latex!&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/matteobettini/benchmarl_sphinx_theme/master/benchmarl_sphinx_theme/static/img/benchmarks/vmas/aggregate_scores.png" alt="aggregate_scores">
&lt;img src="https://raw.githubusercontent.com/matteobettini/benchmarl_sphinx_theme/master/benchmarl_sphinx_theme/static/img/benchmarks/vmas/environemnt_sample_efficiency_curves.png" alt="sample_efficiancy">
&lt;img src="https://raw.githubusercontent.com/matteobettini/benchmarl_sphinx_theme/master/benchmarl_sphinx_theme/static/img/benchmarks/vmas/performance_profile_figure.png" alt="performace_profile">&lt;/p>
&lt;h2 id="configuring">Configuring&lt;/h2>
&lt;p>The project can be configured either the script itself or via &lt;a href="https://hydra.cc/docs/intro/" target="_blank" rel="noopener">hydra&lt;/a>.
Each component in the project has a corresponding yaml configuration in the BenchMARL
&lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf" target="_blank" rel="noopener">conf&lt;/a> tree.
Components&amp;rsquo; configurations are loaded from these files into python dataclasses that act as schemas for
validation of parameter names and types. That way we keep the best of both words: separation of all
configuration from code and strong typing for validation! You can also directly load and validate
configuration yaml files without using hydra from a script by calling &lt;code>ComponentConfig.get_from_yaml()&lt;/code>.&lt;/p>
&lt;p>Here are some examples on how you can override configurations:&lt;/p>
&lt;h4 id="experiments">Experiments&lt;/h4>
&lt;pre>&lt;code class="language-bash">python benchmarl/run.py task=vmas/balance algorithm=mappo experiment.lr=0.03 experiment.evaluation=true experiment.train_device=&amp;quot;cpu&amp;quot;
&lt;/code>&lt;/pre>
&lt;h4 id="algorithms">Algorithms&lt;/h4>
&lt;pre>&lt;code class="language-bash">python benchmarl/run.py task=vmas/balance algorithm=masac algorithm.num_qvalue_nets=3 algorithm.target_entropy=auto algorithm.share_param_critic=true
&lt;/code>&lt;/pre>
&lt;h4 id="tasks">Tasks&lt;/h4>
&lt;p>Be careful, for benchmarking stability this is not suggested.&lt;/p>
&lt;pre>&lt;code class="language-bash">python benchmarl/run.py task=vmas/balance algorithm=mappo task.n_agents=4
&lt;/code>&lt;/pre>
&lt;h4 id="models">Models&lt;/h4>
&lt;pre>&lt;code class="language-bash">python benchmarl/run.py task=vmas/balance algorithm=mappo model=sequence &amp;quot;model.intermediate_sizes=[256]&amp;quot; &amp;quot;model/layers@model.layers.l1=mlp&amp;quot; &amp;quot;model/layers@model.layers.l2=mlp&amp;quot; &amp;quot;+model/layers@model.layers.l3=mlp&amp;quot; &amp;quot;model.layers.l3.num_cells=[3]&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Check out the &lt;a href="https://github.com/facebookresearch/BenchMARL#configuring" target="_blank" rel="noopener">section on how to configure BenchMARL&lt;/a> and
our &lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/examples/configuring" target="_blank" rel="noopener">examples&lt;/a>.&lt;/p>
&lt;h2 id="extending">Extending&lt;/h2>
&lt;p>One of the core tenets of BenchMARL is allowing users to leverage the existing algorithm
and tasks implementations to benchmark their newly proposed solution.&lt;/p>
&lt;p>For this reason we expose standard interfaces with simple abstract methods
for &lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/algorithms/common.py" target="_blank" rel="noopener">algorithms&lt;/a>,
&lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/environments/common.py" target="_blank" rel="noopener">tasks&lt;/a> and
&lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/models/common.py" target="_blank" rel="noopener">models&lt;/a>.
To introduce your solution in the library, you just need to implement the abstract methods
exposed by these base classes which use objects from the &lt;a href="https://github.com/pytorch/rl" target="_blank" rel="noopener">TorchRL&lt;/a> library.&lt;/p>
&lt;p>Here is an &lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/examples/extending/algorithm" target="_blank" rel="noopener">example on how you can create a custom algorithm&lt;/a>.&lt;/p>
&lt;p>Here is an &lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/examples/extending/task" target="_blank" rel="noopener">example on how you can create a custom task&lt;/a>.&lt;/p>
&lt;p>Here is an &lt;a href="https://github.com/facebookresearch/BenchMARL/tree/main/examples/extending/model" target="_blank" rel="noopener">example on how you can create a custom model&lt;/a>.&lt;/p>
&lt;h1 id="next-steps">Next steps&lt;/h1>
&lt;p>BenchMARL is just born and is constantly looking for collaborators to extend and improve its capabilities.
&lt;strong>If you are interested in joining the project, please reach out!&lt;/strong>&lt;/p>
&lt;p>The next steps will include extending the library as well as fine-tuning sets of benchmark hyperparameters
to make them available to the community.&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>&lt;em>Gorsane, Rihab, et al. &amp;ldquo;Towards a standardised performance evaluation protocol
for cooperative marl.&amp;rdquo; Advances in Neural Information Processing Systems 35 (2022): 5510-5521.&lt;/em>&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&amp;#160;&lt;a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Slides</title><link>https://matteobettini.github.io/slides/example/</link><pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/slides/example/</guid><description>&lt;h1 id="create-slides-in-markdown-with-wowchemy">Create slides in Markdown with Wowchemy&lt;/h1>
&lt;p>&lt;a href="https://wowchemy.com/" target="_blank" rel="noopener">Wowchemy&lt;/a> | &lt;a href="https://owchemy.com/docs/managing-content/#create-slides" target="_blank" rel="noopener">Documentation&lt;/a>&lt;/p>
&lt;hr>
&lt;h2 id="features">Features&lt;/h2>
&lt;ul>
&lt;li>Efficiently write slides in Markdown&lt;/li>
&lt;li>3-in-1: Create, Present, and Publish your slides&lt;/li>
&lt;li>Supports speaker notes&lt;/li>
&lt;li>Mobile friendly slides&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="controls">Controls&lt;/h2>
&lt;ul>
&lt;li>Next: &lt;code>Right Arrow&lt;/code> or &lt;code>Space&lt;/code>&lt;/li>
&lt;li>Previous: &lt;code>Left Arrow&lt;/code>&lt;/li>
&lt;li>Start: &lt;code>Home&lt;/code>&lt;/li>
&lt;li>Finish: &lt;code>End&lt;/code>&lt;/li>
&lt;li>Overview: &lt;code>Esc&lt;/code>&lt;/li>
&lt;li>Speaker notes: &lt;code>S&lt;/code>&lt;/li>
&lt;li>Fullscreen: &lt;code>F&lt;/code>&lt;/li>
&lt;li>Zoom: &lt;code>Alt + Click&lt;/code>&lt;/li>
&lt;li>&lt;a href="https://github.com/hakimel/reveal.js#pdf-export" target="_blank" rel="noopener">PDF Export&lt;/a>: &lt;code>E&lt;/code>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="code-highlighting">Code Highlighting&lt;/h2>
&lt;p>Inline code: &lt;code>variable&lt;/code>&lt;/p>
&lt;p>Code block:&lt;/p>
&lt;pre>&lt;code class="language-python">porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
print(&amp;quot;Eating...&amp;quot;)
&lt;/code>&lt;/pre>
&lt;hr>
&lt;h2 id="math">Math&lt;/h2>
&lt;p>In-line math: $x + y = z$&lt;/p>
&lt;p>Block math:&lt;/p>
&lt;p>$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p>
&lt;hr>
&lt;h2 id="fragments">Fragments&lt;/h2>
&lt;p>Make content appear incrementally&lt;/p>
&lt;pre>&lt;code>{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code>&lt;/pre>
&lt;p>Press &lt;code>Space&lt;/code> to play!&lt;/p>
&lt;span class="fragment " >
One
&lt;/span>
&lt;span class="fragment " >
**Two**
&lt;/span>
&lt;span class="fragment " >
Three
&lt;/span>
&lt;hr>
&lt;p>A fragment can accept two optional parameters:&lt;/p>
&lt;ul>
&lt;li>&lt;code>class&lt;/code>: use a custom style (requires definition in custom CSS)&lt;/li>
&lt;li>&lt;code>weight&lt;/code>: sets the order in which a fragment appears&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="speaker-notes">Speaker Notes&lt;/h2>
&lt;p>Add speaker notes to your presentation&lt;/p>
&lt;pre>&lt;code class="language-markdown">{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code>&lt;/pre>
&lt;p>Press the &lt;code>S&lt;/code> key to view the speaker notes!&lt;/p>
&lt;aside class="notes">
&lt;ul>
&lt;li>Only the speaker can read these notes&lt;/li>
&lt;li>Press &lt;code>S&lt;/code> key to view&lt;/li>
&lt;/ul>
&lt;/aside>
&lt;hr>
&lt;h2 id="themes">Themes&lt;/h2>
&lt;ul>
&lt;li>black: Black background, white text, blue links (default)&lt;/li>
&lt;li>white: White background, black text, blue links&lt;/li>
&lt;li>league: Gray background, white text, blue links&lt;/li>
&lt;li>beige: Beige background, dark text, brown links&lt;/li>
&lt;li>sky: Blue background, thin dark text, blue links&lt;/li>
&lt;/ul>
&lt;hr>
&lt;ul>
&lt;li>night: Black background, thick white text, orange links&lt;/li>
&lt;li>serif: Cappuccino background, gray text, brown links&lt;/li>
&lt;li>simple: White background, black text, blue links&lt;/li>
&lt;li>solarized: Cream-colored background, dark green text, blue links&lt;/li>
&lt;/ul>
&lt;hr>
&lt;section data-noprocess data-shortcode-slide
data-background-image="/media/boards.jpg"
>
&lt;h2 id="custom-slide">Custom Slide&lt;/h2>
&lt;p>Customize the slide style and background&lt;/p>
&lt;pre>&lt;code class="language-markdown">{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code>&lt;/pre>
&lt;hr>
&lt;h2 id="custom-css-example">Custom CSS Example&lt;/h2>
&lt;p>Let&amp;rsquo;s make headers navy colored.&lt;/p>
&lt;p>Create &lt;code>assets/css/reveal_custom.css&lt;/code> with:&lt;/p>
&lt;pre>&lt;code class="language-css">.reveal section h1,
.reveal section h2,
.reveal section h3 {
color: navy;
}
&lt;/code>&lt;/pre>
&lt;hr>
&lt;h1 id="questions">Questions?&lt;/h1>
&lt;p>&lt;a href="https://github.com/wowchemy/wowchemy-hugo-modules/discussions" target="_blank" rel="noopener">Ask&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://wowchemy.com/docs/managing-content/#create-slides" target="_blank" rel="noopener">Documentation&lt;/a>&lt;/p></description></item><item><title>External Project</title><link>https://matteobettini.github.io/project/external-project/</link><pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/project/external-project/</guid><description/></item><item><title>Internal Project</title><link>https://matteobettini.github.io/project/internal-project/</link><pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/project/internal-project/</guid><description>&lt;p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p>
&lt;p>Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p>
&lt;p>Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p>
&lt;p>Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p>
&lt;p>Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p></description></item><item><title/><link>https://matteobettini.github.io/admin/config.yml</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://matteobettini.github.io/admin/config.yml</guid><description/></item></channel></rss>