<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.2.0 for Hugo"><meta name=author content="Matteo Bettini"><meta name=description content="PhD Candidate"><link rel=alternate hreflang=en-us href=https://matteobettini.github.io/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#4caf50"><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.08a6e39f78f6b42de9dcc39ef8155d7d.css><script src=https://identity.netlify.com/v1/netlify-identity-widget.js></script>
<link rel=alternate href=/index.xml type=application/rss+xml title="Matteo Bettini"><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://matteobettini.github.io/><meta property="twitter:card" content="summary"><meta property="og:site_name" content="Matteo Bettini"><meta property="og:url" content="https://matteobettini.github.io/"><meta property="og:title" content="Matteo Bettini"><meta property="og:description" content="PhD Candidate"><meta property="og:image" content="https://matteobettini.github.io/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://matteobettini.github.io/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2030-06-01T13:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","potentialAction":{"@type":"SearchAction","target":"https://matteobettini.github.io/?q={search_term_string}","query-input":"required name=search_term_string"},"url":"https://matteobettini.github.io/"}</script><title>Matteo Bettini</title></head><body id=top data-spy=scroll data-offset=70 data-target=#navbar-main class=page-wrapper data-wc-page-id=3976528693a0108357f4928017600865><script src=/js/wowchemy-init.min.4be02a3b391999348b0c7478778a0e4b.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Matteo Bettini</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Matteo Bettini</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#featured data-target=#featured><span>Featured</span></a></li><li class=nav-item><a class=nav-link href=/#publications data-target=#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#contact data-target=#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><span class="js-widget-page d-none"></span><section id=about class="home-section wg-about"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4"><div id=profile><img class="avatar avatar-circle" src=/authors/admin/avatar_hu9ce315dca9917080fc2f5a7d235ccd99_954972_270x270_fill_q100_lanczos_center.jpeg alt="Matteo Bettini"><div class=portrait-title><h2>Matteo Bettini</h2><h3>PhD Candidate</h3><h3><a href=https://www.proroklab.org/?team target=_blank rel=noopener><span>Prorok Lab</span></a></h3><h3><a href=https://www.cst.cam.ac.uk/ target=_blank rel=noopener><span>University of Cambridge</span></a></h3></div><ul class=network-icon aria-hidden=true><li><a href=/#contact aria-label=envelope><i class="fas fa-envelope big-icon"></i></a></li><li><a href="https://scholar.google.com/citations?user=hcvR_W0AAAAJ" target=_blank rel=noopener aria-label=google-scholar><i class="ai ai-google-scholar big-icon"></i></a></li><li><a href=https://www.semanticscholar.org/author/Matteo-Bettini/2153781474 target=_blank rel=noopener aria-label=semantic-scholar><i class="ai ai-semantic-scholar big-icon"></i></a></li><li><a href=https://github.com/matteobettini target=_blank rel=noopener aria-label=github><i class="fab fa-github big-icon"></i></a></li><li><a href=https://linkedin.com/in/bettinimatteo target=_blank rel=noopener aria-label=linkedin><i class="fab fa-linkedin big-icon"></i></a></li><li><a href=http://www.youtube.com/@matteobettini1871 target=_blank rel=noopener aria-label=youtube><i class="fab fa-youtube big-icon"></i></a></li><li><a href=/uploads/Matteo_bettini___CV.pdf aria-label=cv><i class="ai ai-cv big-icon"></i></a></li></ul></div></div><div class="col-12 col-lg-8"><div class=article-style><h3 id=hello->Hello! ðŸ‘‹</h3><h4 id=i-am-matteo-a-phd-student-in-the-prorok-lab-at-the-university-of-cambridge>I am Matteo, a PhD student in the Prorok Lab at the University of Cambridge.</h4><p>With my supervisor, <a href=https://www.proroklab.org/ target=_blank rel=noopener>Amanda Prorok</a>, I study resilience and heterogeneity in multi-agent and multi-robot systems. For my research, I employ techniques from the fields of Multi-Agent Reinforcement Learning and Graph Neural Networks.</p><p>Prior to my PhD, I investigated the problem of transport network design for multi-agent routing.</p><p><i class="fas fa-download pr-1 fa-fw"></i> Download my <a href=/uploads/Matteo_bettini___CV.pdf target=_blank>CV</a>.</p></div><div class=row><div class=col-md-5><div class=section-subheading>Interests</div><ul class="ul-interests mb-0"><li>Multi-Robot Systems</li><li>Heterogeneous Multi-Agent Learning and Coordination</li><li>Reinforcement Learning</li><li>Graph Neural Networks</li></ul></div><div class=col-md-7><div class=section-subheading>Education</div><ul class="ul-edu fa-ul mb-0"><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>PhD in Computer Science, Present</p><p class=institution>University of Cambridge</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>MPhil in Advanced Computer Science, 2021</p><p class=institution>University of Cambridge</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>BEng in Computer Engineering, 2020</p><p class=institution>Politecnico di Milano</p></div></li></ul></div></div></div></div></div></section><section id=featured class="home-section wg-featured"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Featured Publications</h1></div><div class="col-12 col-lg-8"><div class=card-simple><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/kortvelesy/>Ryan Kortvelesy</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>International Conference on Machine Learning (ICML)</em></span></div><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/><img src=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/featured_hu9dca1e83ecb59c40dcc79a7f11d4d205_4216083_808x455_fit_q90_lanczos.gif class=article-banner alt="Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning" loading=lazy></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/>Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning</a></div><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/ class=summary-link><div class=article-style><p>We introduce Diversity Control (DiCo), a method able to control diversity to an exact value of a given metric by representing policies as the sum of a parameter-shared component and dynamically scaled per-agent components. By applying constraints directly to the policy architecture, DiCo leaves the learning objective unchanged, enabling its applicability to any actor-critic MARL algorithm. We theoretically prove that DiCo achieves the desired diversity, and we provide several experiments, both in cooperative and competitive tasks, that show how DiCo can be employed as a novel paradigm to increase performance and sample efficiency in MARL.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/Controlling-Behavioral-Diversity-in-Multi-Agent-Reinforcement-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/ControllingBehavioralDiversity target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://sites.google.com/view/dico-marl target=_blank rel=noopener>Website</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=qQjUgItPq4" target=_blank rel=noopener>OpenReview</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2405.15054 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/poster.pdf>Poster</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/ImcuXnmX43g target=_blank rel=noopener>Talk</a></div></div><div class=card-simple><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span>, <span><a href=/authors/vincent-moens/>Vincent Moens</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Journal of Machine Learning Research (JMLR)</em></span></div><a href=/publication/benchmarl/><img src=/publication/benchmarl/featured_hu61ea57729c9eea7664f9ac410fbef93f_1166554_808x455_fit_q90_lanczos.jpg class=article-banner alt="BenchMARL: Benchmarking Multi-Agent Reinforcement Learning" loading=lazy></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/benchmarl/>BenchMARL: Benchmarking Multi-Agent Reinforcement Learning</a></div><a href=/publication/benchmarl/ class=summary-link><div class=article-style><p>BenchMARL is a library for benchmarking Multi-Agent Reinforcement Learning (MARL) using TorchRL. BenchMARL allows to quickly compare different MARL algorithms, tasks, and models while being systematically grounded in its two core tenets: reproducibility and standardization.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/benchmarl/BenchMARL.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/benchmarl/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/facebookresearch/BenchMARL target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://benchmarl.readthedocs.io/ target=_blank rel=noopener>Docs</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://wandb.ai/matteobettini/benchmarl-public/reportlist target=_blank rel=noopener>Wandb Benchmarks</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=1tOIMgJf_VQ" target=_blank rel=noopener>Talk</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2312.01472 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/benchmarl/poster.pdf>Poster</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=http://jmlr.org/papers/v25/23-1612.html target=_blank rel=noopener>Proceedings</a></div></div></div></div></div></section><section id=publications class="home-section wg-portfolio"><div class=home-section-bg></div><div class=container><div class="row justify-content-center"><div class="section-heading col-12 mb-3 text-center"><h1 class=mb-0>Publications</h1></div><div class=col-12><p>To find relevant content, try <a href=./publication/>searching publications</a> or filtering using the buttons below.</p><span class="d-none default-project-filter">*</span><div class=project-toolbar><div class=project-filters><div class=btn-toolbar><div class="btn-group flex-wrap"><a href=# data-filter=* class="btn btn-primary btn-lg active">All</a>
<a href=# data-filter=.js-id-Heterogeneity class="btn btn-primary btn-lg">Heterogeneity</a>
<a href=# data-filter=.js-id-Multi-Agent-Reinforcement-Learning class="btn btn-primary btn-lg">Multi-Agent Reinforcement Learning</a>
<a href=# data-filter=.js-id-Software-library class="btn btn-primary btn-lg">Software library</a></div></div></div></div><div class="isotope projects-container row js-layout-row"><div class="col-12 isotope-item js-id-Heterogeneity js-id-Multi-Agent-Reinforcement-Learning"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/heterogeneous-teams/>Heterogeneous Teams</a></div><a href=/publication/heterogeneous-teams/ class=summary-link><div class=article-style>The aim of this chapter is to provide an overview of heterogeneous teams, from a robotics perspective.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/authors/prorok/>Amanda Prorok</a></span>, <span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Encyclopedia of Robotics</em></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/heterogeneous-teams/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://link.springer.com/referenceworkentry/10.1007/978-3-642-41610-1_230-1 target=_blank rel=noopener>Springer link</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/heterogeneous-teams/><img src=/publication/heterogeneous-teams/compact_hud59ed9e7a0b39e8d92b1aece9a7e9e9d_209553_300x0_resize_q100_lanczos.jpg alt="Heterogeneous Teams" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Multi-Agent-Reinforcement-Learning js-id-Heterogeneity"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/>Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning</a></div><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/ class=summary-link><div class=article-style>We introduce Diversity Control (DiCo), a method able to control diversity to an exact value of a given metric by representing policies as the sum of a parameter-shared component and dynamically scaled per-agent components. By applying constraints directly to the policy architecture, DiCo leaves the learning objective unchanged, enabling its applicability to any actor-critic MARL algorithm. We theoretically prove that DiCo achieves the desired diversity, and we provide several experiments, both in cooperative and competitive tasks, that show how DiCo can be employed as a novel paradigm to increase performance and sample efficiency in MARL.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/kortvelesy/>Ryan Kortvelesy</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>International Conference on Machine Learning (ICML)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/Controlling-Behavioral-Diversity-in-Multi-Agent-Reinforcement-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/ControllingBehavioralDiversity target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://sites.google.com/view/dico-marl target=_blank rel=noopener>Website</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=qQjUgItPq4" target=_blank rel=noopener>OpenReview</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2405.15054 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/poster.pdf>Poster</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/ImcuXnmX43g target=_blank rel=noopener>Talk</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/><img src=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/compact_hu9dca1e83ecb59c40dcc79a7f11d4d205_4216083_300x0_resize_lanczos.gif alt="Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Multi-Agent-Reinforcement-Learning"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/robomaster/>The Cambridge RoboMaster: An Agile Multi-Robot Research Platform</a></div><a href=/publication/robomaster/ class=summary-link><div class=article-style>This article introduces a tightly integrated hardware, control, and simulation software stack on a fleet of holonomic ground robot platforms. Our robots, a fleet of customised DJI Robomaster S1 vehicles, offer a balance between small robots that do not possess sufficient compute or actuation capabilities and larger robots that are unsuitable for indoor multi-robot tests.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/authors/blumenkamp/>Jan Blumenkamp</a></span>, <span><a href=/authors/shankar/>Ajay Shankar</a></span>, <span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/joshua-bird/>Joshua Bird</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Distributed Autonomous Robotic Systems (DARS)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/robomaster/robomaster.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/robomaster/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/cambridge-robomaster target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://proroklab.github.io/cambridge-robomaster/supplementary.html#vmas-deployment target=_blank rel=noopener>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://proroklab.github.io/cambridge-robomaster/ target=_blank rel=noopener>Docs</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2405.02198 target=_blank rel=noopener>arXiv</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/robomaster/><img src=/publication/robomaster/compact_hu46efff4e28ca506a88be1427516cbd21_2261186_300x0_resize_lanczos_3.png alt="The Cambridge RoboMaster: An Agile Multi-Robot Research Platform" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Multi-Agent-Reinforcement-Learning js-id-Software-library"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/benchmarl/>BenchMARL: Benchmarking Multi-Agent Reinforcement Learning</a></div><a href=/publication/benchmarl/ class=summary-link><div class=article-style>BenchMARL is a library for benchmarking Multi-Agent Reinforcement Learning (MARL) using TorchRL. BenchMARL allows to quickly compare different MARL algorithms, tasks, and models while being systematically grounded in its two core tenets: reproducibility and standardization.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span>, <span><a href=/authors/vincent-moens/>Vincent Moens</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Journal of Machine Learning Research (JMLR)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/benchmarl/BenchMARL.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/benchmarl/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/facebookresearch/BenchMARL target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://benchmarl.readthedocs.io/ target=_blank rel=noopener>Docs</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://wandb.ai/matteobettini/benchmarl-public/reportlist target=_blank rel=noopener>Wandb Benchmarks</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=1tOIMgJf_VQ" target=_blank rel=noopener>Talk</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2312.01472 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/benchmarl/poster.pdf>Poster</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=http://jmlr.org/papers/v25/23-1612.html target=_blank rel=noopener>Proceedings</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/benchmarl/><img src=/publication/benchmarl/compact_hu0971da7d7467813a850f11c8b39be638_3051643_300x0_resize_lanczos_3.png alt="BenchMARL: Benchmarking Multi-Agent Reinforcement Learning" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Multi-Agent-Reinforcement-Learning js-id-Software-library"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/>TorchRL: A data-driven decision-making library for PyTorch</a></div><a href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/ class=summary-link><div class=article-style>We propose TorchRL, a generalistic control library for PyTorch that provides well-integrated, yet standalone components. With a versatile and robust primitive design, TorchRL facilitates streamlined algorithm development across the many branches of Reinforcement Learning (RL) and control. We introduce a new PyTorch primitive, TensorDict, as a flexible data carrier that empowers the integration of the libraryâ€™s components while preserving their modularity. TorchRL fosters long-term support and is publicly available on GitHub for greater reproducibility and collaboration within the research community.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/authors/albert-bou/>Albert Bou</a></span>, <span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/sebastian-dittert/>Sebastian Dittert</a></span>, <span><a href=/authors/vikash-kumar/>Vikash Kumar</a></span>, <span><a href=/authors/shagun-sodhani/>Shagun Sodhani</a></span>, <span><a href=/authors/xiaomeng-yang/>Xiaomeng Yang</a></span>, <span><a href=/authors/gianni-de-fabritiis/>Gianni De Fabritiis</a></span>, <span><a href=/authors/vincent-moens/>Vincent Moens</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>International Conference on Learning Representations (ICLR)</em> - <strong><em>Spotlight (top 5%)</em></strong></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/TorchRL-A-data-driven-decision-making-library-for-PyTorch.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/pytorch/rl target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://pytorch.org/rl/ target=_blank rel=noopener>Documentation</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2306.00577 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=QxItoEAVMb" target=_blank rel=noopener>OpenReview</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/poster.pdf>Poster</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/><img src=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/compact_hu903fd55680461821a9b538ed6f8cf6de_77481_300x0_resize_lanczos_3.png alt="TorchRL: A data-driven decision-making library for PyTorch" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Heterogeneity js-id-Multi-Agent-Reinforcement-Learning"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/>System Neural Diversity: Measuring Behavioral Heterogeneity in Multi-Agent Learning</a></div><a href=/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/ class=summary-link><div class=article-style>In this paper, we introduce System Neural Diversity (SND): a measure of behavioral heterogeneity for multi-agent systems where agents have stochastic policies. We discuss and prove its theoretical properties, and compare it with alternate, state-of-the-art behavioral diversity metrics used in cross-disciplinary domains. Through simulations of a variety of multi-agent tasks, we show how our metric constitutes an important diagnostic tool to analyze latent properties of behavioral heterogeneity.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/shankar/>Ajay Shankar</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2023</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Preprint</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/System-Neural-Diversity-Measuring-Behavioral-Heterogeneity-in-Multi-Agent-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/HetGPPO target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2305.02128 target=_blank rel=noopener>arXiv</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/><img src=/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/compact_hu1e3587a73e760af3ad1dedea38e4387a_749078_300x0_resize_lanczos_3.png alt="System Neural Diversity: Measuring Behavioral Heterogeneity in Multi-Agent Learning" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Heterogeneity js-id-Multi-Agent-Reinforcement-Learning"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/heterogeneous-multi-robot-reinforcement-learning/>Heterogeneous Multi-Robot Reinforcement Learning</a></div><a href=/publication/heterogeneous-multi-robot-reinforcement-learning/ class=summary-link><div class=article-style>In this paper, we crystallize the role of heterogeneity in MARL policies. We introduce Heterogeneous Graph Neural Network Proximal Policy Optimization (HetGPPO), a paradigm for training heterogeneous MARL policies that leverages a Graph Neural Network for differentiable inter-agent communication. HetGPPO allows communicating agents to learn heterogeneous behaviors while enabling fully decentralized training in partially observable environments. Through simulations and real-world experiments, we show that: (i) when homogeneous methods fail due to strong heterogeneous requirements, HetGPPO succeeds, and, (ii) when homogeneous methods are able to learn apparently heterogeneous behaviors, HetGPPO achieves higher resilience to both training and deployment noise.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/shankar/>Ajay Shankar</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2023</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Autonomous Agents and Multiagent Systems (AAMAS)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/heterogeneous-multi-robot-reinforcement-learning/Heterogeneous-Multi-Robot-Reinforcement-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/heterogeneous-multi-robot-reinforcement-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/HetGPPO target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=J81IVQEy-zw" target=_blank rel=noopener>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2301.07137 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=a4md0es3kuo" target=_blank rel=noopener>Talk</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/heterogeneous-multi-robot-reinforcement-learning/poster.pdf>Poster</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/heterogeneous-multi-robot-reinforcement-learning/><img src=/publication/heterogeneous-multi-robot-reinforcement-learning/compact_hu1234d6e5d8e0fe29abec561068287070_2300259_300x0_resize_lanczos_3.png alt="Heterogeneous Multi-Robot Reinforcement Learning" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Software-library"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/>POPGym: Benchmarking Partially Observable Reinforcement Learning</a></div><a href=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/ class=summary-link><div class=article-style>We introduce Partially Observable Process Gym (POPGym), a two-part library containing (1) a diverse collection of 14 partially observable environments, each with multiple difficulties and (2) implementations of 13 memory model baselines â€“ the most in a single RL library. Using POPGym, we execute the largest comparison across RL memory models to date.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/authors/morad/>Steven Morad</a></span>, <span><a href=/authors/kortvelesy/>Ryan Kortvelesy</a></span>, <span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/stephan-liwicki/>Stephan Liwicki</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2023</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>International Conference on Learning Representations (ICLR)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/POPGym-Benchmarking-Partially-Observable-Reinforcement-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/smorad/popgym target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2303.01859 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=chDrutUTs0K" target=_blank rel=noopener>OpenReview</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/poster.png>Poster</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/><img src=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/compact_hu08087b80d13a316aaceae06d8ed23885_323361_300x0_resize_lanczos_3.png alt="POPGym: Benchmarking Partially Observable Reinforcement Learning" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Multi-Agent-Reinforcement-Learning js-id-Software-library"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/>VMAS: A Vectorized Multi-Agent Simulator for Collective Robot Learning</a></div><a href=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/ class=summary-link><div class=article-style>In this paper, we introduce the Vectorized Multi-Agent Simulator (VMAS). VMAS is an open-source framework designed for efficient MARL benchmarking. It comprises a vectorized 2D physics engine written in PyTorch and a set of twelve challenging multi-robot scenarios. Additional scenarios can be implemented through a simple and modular interface. We demonstrate how vectorization enables parallel simulation on accelerated hardware without added complexity.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/kortvelesy/>Ryan Kortvelesy</a></span>, <span><a href=/authors/blumenkamp/>Jan Blumenkamp</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2022</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Distributed Autonomous Robotic Systems (DARS)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/VMAS-A-Vectorized-Multi-Agent-Simulator-for-Collective-Robot-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/VectorizedMultiAgentSimulator target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=aaDRYfiesAY&t=1s" target=_blank rel=noopener>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2207.03530 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/boViBY7Woqg target=_blank rel=noopener>Talk</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/><img src=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/compact_hua4f5b9e0add8e9e8c3203a579e61fbd6_755644_300x0_resize_lanczos_3.png alt="VMAS: A Vectorized Multi-Agent Simulator for Collective Robot Learning" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Transport-Network-Design"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/on-the-properties-of-path-additions-for-traffic-routing/>On the Properties of Path Additions for Traffic Routing</a></div><a href=/publication/on-the-properties-of-path-additions-for-traffic-routing/ class=summary-link><div class=article-style>In this paper, we investigate the impact of path additions to transport networks with optimised traffic routing. In particular, we study the behaviour of total travel time, and consider both self-interested routing paradigms, such as User Equilibrium (UE) routing, as well as cooperative paradigms, such as classic Multi-Commodity (MC) network flow and System Optimal (SO) routing. This work aims to provide an analysis and categorization of the properties of objective functions for transport network design, with the purpose of informing algorithm (and also network) designers. Among our results, we prove, via counterexample, that total travel time, under both cooperative and self-interested routing, is not supermodular with respect to path additions.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2022</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>IEEE International Conference on Intelligent Transportation Systems (ITSC) Workshop on Co-Design and Coordination of Future Mobility Systems</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/on-the-properties-of-path-additions-for-traffic-routing/On-the-properties-of-path-additions-for-traffic-routing.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/on-the-properties-of-path-additions-for-traffic-routing/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/matteobettini/Traffic-Assignment-Frank-Wolfe-2021 target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2207.04505 target=_blank rel=noopener>arXiv</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/on-the-properties-of-path-additions-for-traffic-routing/><img src=/publication/on-the-properties-of-path-additions-for-traffic-routing/compact_hub80e700c5eadfc1ac79e44fc5dc02fe5_506162_300x0_resize_lanczos_3.png alt="On the Properties of Path Additions for Traffic Routing" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/mphil-thesis/>Transport network design for vehicle routing: results on path addition and capacity reduction</a></div><a href=/publication/mphil-thesis/ class=summary-link><div class=article-style>In this thesis, we investigate the problem of optimising the transportation network for AVs both from a theoretical and from a practical perspective. In the first part, we investigate the properties of adding paths to a network and we prove that path additions to transport networks, where AVs are routed, are not supermodular in travel time, extending the seminal result of Braessâ€™ paradox. In the second part, we formulate two network design problems for self-interested AVs. We present the problem of optimising transport networks via path additions and a novel problem design where self-interested users are guided towards optimal paths through the reduction of road capacities. Through capacity reductions, we achieve significant total travel time improvements on six real-world transport networks: Anaheim (USA), Barcelona (Spain), Chicago (USA), Eastern Massachusetts (USA), Sioux Falls (USA), and Winnipeg (Canada). For instance, we improve the Chicago network by up to 7%, saving more than 487 hours of total travel time per traffic hour.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span></div><span class=article-date>2021</span>
<span class=middot-divider></span>
<span class=pub-publication>MPhil Thesis</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/mphil-thesis/mphil-thesis.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/mphil-thesis/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/matteobettini/Traffic-Assignment-Frank-Wolfe-2021 target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/FPbyjnwUizQ target=_blank rel=noopener>Video</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/mphil-thesis/><img src=/publication/mphil-thesis/compact_hu9662cb3a79fd0a9108ceaf2b615f454b_168090_300x0_resize_lanczos_3.png alt="Transport network design for vehicle routing: results on path addition and capacity reduction" loading=lazy></a></div></div></div></div></div></div></div></div></section><section id=contact class="home-section wg-contact"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Contact</h1></div><div class="col-12 col-lg-8"><ul class=fa-ul><li><i class="fa-li fas fa-envelope fa-2x" aria-hidden=true></i>
<span id=person-email><a href=mailto:mb2389@cl.cam.ac.uk>mb2389@cl.cam.ac.uk</a></span></li><li><i class="fa-li fas fa-map-marker fa-2x" aria-hidden=true></i>
<span id=person-address>Office SN05, Department of Computer Science and Technology, William Gates Building, 15 JJ Thomson Avenue, Cambridge, CB3 0FD</span></li><li><i class="fa-li fas fa-users fa-2x" aria-hidden=true></i>
<a href=https://www.proroklab.org// target=_blank rel=noopener>Prorok Lab</a></li><li><i class="fa-li ai ai-google-scholar fa-2x" aria-hidden=true></i>
<a href="https://scholar.google.com/citations?user=hcvR_W0AAAAJ" target=_blank rel=noopener>Google Scholar</a></li><li><i class="fa-li ai ai-semantic-scholar fa-2x" aria-hidden=true></i>
<a href=https://www.semanticscholar.org/author/Matteo-Bettini/2153781474 target=_blank rel=noopener>Semantic Scholar</a></li><li><i class="fa-li fab fa-github fa-2x" aria-hidden=true></i>
<a href=https://github.com/matteobettini target=_blank rel=noopener>GitHub</a></li><li><i class="fa-li fab fa-linkedin fa-2x" aria-hidden=true></i>
<a href=https://www.linkedin.com/in/bettinimatteo/ target=_blank rel=noopener>Linkedin</a></li><li><i class="fa-li fab fa-youtube fa-2x" aria-hidden=true></i>
<a href=http://www.youtube.com/@matteobettini1871 target=_blank rel=noopener>YouTube</a></li></ul><div class=d-none><input id=map-provider value=mapnik>
<input id=map-lat value=52.21123696078217>
<input id=map-lng value=0.09206671555446201>
<input id=map-dir value="Office SN05, Department of Computer Science and Technology, William Gates Building, 15 JJ Thomson Avenue, Cambridge, CB3 0FD">
<input id=map-zoom value=16>
<input id=map-api-key value></div><div id=map></div></div></div></div></section></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>View <a href=https://github.com/matteobettini/professional_website target=_blank rel=noopener>source</a>.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script>
<script src=/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script>
<script src=/en/js/wowchemy.min.26bc5a5b73c468c9e767656a378ac5e3.js></script>
<script async defer src=https://buttons.github.io/buttons.js></script></body></html>