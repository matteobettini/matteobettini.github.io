<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.2.0 for Hugo"><meta name=author content="Matteo Bettini"><meta name=description content="Researcher"><link rel=alternate hreflang=en-us href=https://matteobettini.github.io/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#4caf50"><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.08a6e39f78f6b42de9dcc39ef8155d7d.css><script src=https://identity.netlify.com/v1/netlify-identity-widget.js></script>
<link rel=alternate href=/index.xml type=application/rss+xml title="Matteo Bettini"><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://matteobettini.github.io/><meta property="twitter:card" content="summary"><meta property="og:site_name" content="Matteo Bettini"><meta property="og:url" content="https://matteobettini.github.io/"><meta property="og:title" content="Matteo Bettini"><meta property="og:description" content="Researcher"><meta property="og:image" content="https://matteobettini.github.io/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://matteobettini.github.io/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2030-06-01T13:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","potentialAction":{"@type":"SearchAction","target":"https://matteobettini.github.io/?q={search_term_string}","query-input":"required name=search_term_string"},"url":"https://matteobettini.github.io/"}</script><title>Matteo Bettini</title></head><body id=top data-spy=scroll data-offset=70 data-target=#navbar-main class=page-wrapper data-wc-page-id=3976528693a0108357f4928017600865><script src=/js/wowchemy-init.min.4be02a3b391999348b0c7478778a0e4b.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Matteo Bettini</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Matteo Bettini</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#featured data-target=#featured><span>Featured</span></a></li><li class=nav-item><a class=nav-link href=/#publications data-target=#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#contact data-target=#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><span class="js-widget-page d-none"></span><section id=about class="home-section wg-about"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4"><div id=profile><img class="avatar avatar-circle" src=/authors/admin/avatar_hu9ce315dca9917080fc2f5a7d235ccd99_954972_270x270_fill_q100_lanczos_center.jpeg alt="Matteo Bettini"><div class=portrait-title><h2>Matteo Bettini</h2><h3>Researcher</h3><h3><a href=https://ai.meta.com/ target=_blank rel=noopener><span>Meta</span></a></h3><h3><a href=https://www.cst.cam.ac.uk/ target=_blank rel=noopener><span>University of Cambridge</span></a></h3></div><ul class=network-icon aria-hidden=true><li><a href=/#contact aria-label=envelope><i class="fas fa-envelope big-icon"></i></a></li><li><a href="https://scholar.google.com/citations?user=hcvR_W0AAAAJ" target=_blank rel=noopener aria-label=google-scholar><i class="ai ai-google-scholar big-icon"></i></a></li><li><a href=https://www.semanticscholar.org/author/Matteo-Bettini/2153781474 target=_blank rel=noopener aria-label=semantic-scholar><i class="ai ai-semantic-scholar big-icon"></i></a></li><li><a href=https://github.com/matteobettini target=_blank rel=noopener aria-label=github><i class="fab fa-github big-icon"></i></a></li><li><a href=https://linkedin.com/in/bettinimatteo target=_blank rel=noopener aria-label=linkedin><i class="fab fa-linkedin big-icon"></i></a></li><li><a href=http://www.youtube.com/@matteobettini1871 target=_blank rel=noopener aria-label=youtube><i class="fab fa-youtube big-icon"></i></a></li><li><a href=/uploads/Matteo_bettini___CV.pdf aria-label=cv><i class="ai ai-cv big-icon"></i></a></li></ul></div></div><div class="col-12 col-lg-8"><div class=article-style><h3 id=hello->Hello! ðŸ‘‹</h3><h4 id=i-am-matteo-a-researcher-in-machine-learning>I am Matteo, a researcher in machine learning.</h4><p>My research focuses on reinforcement learning applied to multi-agent and multi-robot systems.</p><p>I am currently working on training LLM agents for long-horizon tasks using reinforcement learning at Meta.</p><p>I obtained my PhD from the <a href=https://www.proroklab.org/ target=_blank rel=noopener>Prorok Lab</a> at the University of Cambridge,
were I studied heterogeneity in multi-agent and multi-robot systems and developed the <a href=https://github.com/proroklab/VectorizedMultiAgentSimulator target=_blank rel=noopener>VMAS</a> simulator.
For this research, I employed techniques from the fields of Multi-Agent Reinforcement Learning and Graph Neural Networks.
During my PhD, I joined PyTorch at Meta, where I created <a href=https://github.com/facebookresearch/BenchMARL target=_blank rel=noopener>BenchMARL</a> and helped develop <a href=https://github.com/pytorch/rl target=_blank rel=noopener>TorchRL</a>.</p><p>For my master, I investigated the problem of transport network design for multi-agent routing.</p><p><i class="fas fa-download pr-1 fa-fw"></i> See my <a href=/uploads/Matteo_bettini___CV.pdf target=_blank>CV</a> and the (more verbose) <a href=/uploads/Matteo_bettini___CV_academia.pdf target=_blank>academic CV</a>.</p></div><div class=row><div class=col-md-5><div class=section-subheading>Interests</div><ul class="ul-interests mb-0"><li>Reinforcement Learning</li><li>Multi-Robot Systems</li><li>LLM Agents</li><li>Heterogeneous Multi-Agent Learning and Coordination</li><li>Graph Neural Networks</li></ul></div><div class=col-md-7><div class=section-subheading>Education</div><ul class="ul-edu fa-ul mb-0"><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>PhD in Computer Science, 2025</p><p class=institution>University of Cambridge</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>MPhil in Advanced Computer Science, 2021</p><p class=institution>University of Cambridge</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>BEng in Computer Engineering, 2020</p><p class=institution>Politecnico di Milano</p></div></li></ul></div></div></div></div></div></section><section id=featured class="home-section wg-featured"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Featured Publications</h1></div><div class="col-12 col-lg-8"><div class=card-simple><div class=article-metadata><div><span><a href=/authors/pierre-andrews/>Pierre Andrews</a></span>, <span><a href=/authors/amine-benhalloum/>Amine Benhalloum</a></span>, <span><a href=/authors/gerard-moreno-torres-bertran/>Gerard Moreno-Torres Bertran</a></span>, <span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/amar-budhiraja/>Amar Budhiraja</a></span>, <span><a href=/authors/ricardo-silveira-cabral/>Ricardo Silveira Cabral</a></span>, <span><a href=/authors/virginie-do/>Virginie Do</a></span>, <span><a href=/authors/romain-froger/>Romain Froger</a></span>, <span><a href=/authors/emilien-garreau/>Emilien Garreau</a></span>, <span><a href=/authors/jean-baptiste-gaya/>Jean-Baptiste Gaya</a></span>, <span><a href=/authors/hugo-laurencon/>Hugo LaurenÃ§on</a></span>, <span><a href=/authors/maxime-lecanu/>Maxime Lecanu</a></span>, <span><a href=/authors/kunal-malkan/>Kunal Malkan</a></span>, <span><a href=/authors/dheeraj-mekala/>Dheeraj Mekala</a></span>, <span><a href=/authors/pierre-menard/>Pierre MÃ©nard</a></span>, <span><a href=/authors/gregoire-mialon/>GrÃ©goire Mialon</a></span>, <span><a href=/authors/ulyana-piterbarg/>Ulyana Piterbarg</a></span>, <span><a href=/authors/mikhail-plekhanov/>Mikhail Plekhanov</a></span>, <span><a href=/authors/mathieu-rita/>Mathieu Rita</a></span>, <span><a href=/authors/andrey-rusakov/>Andrey Rusakov</a></span>, <span><a href=/authors/thomas-scialom/>Thomas Scialom</a></span>, <span><a href=/authors/vladislav-vorotilov/>Vladislav Vorotilov</a></span>, <span><a href=/authors/mengjue-wang/>Mengjue Wang</a></span>, <span><a href=/authors/ian-yu/>Ian Yu</a></span></div><span class=article-date>2026</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>International Conference on Learning Representations (ICLR)</em> - <strong><em>Oral (top 2%)</em></strong></span></div><a href=/publication/are/><img src=/publication/are/featured_hub262ee4bb15642b1284724f1a6218afe_154991_808x455_fit_q90_lanczos_3.png class=article-banner alt="ARE: Scaling Up Agent Environments and Evaluations" loading=lazy></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/are/>ARE: Scaling Up Agent Environments and Evaluations</a></div><a href=/publication/are/ class=summary-link><div class=article-style><p>We introduce Meta Agents Research Environments (ARE), a research platform for scalable creation of environments, integration of synthetic or real applications, and execution of agentic orchestrations. We also propose Gaia2, a benchmark built in ARE and designed to measure general agent capabilities. Unlike prior benchmarks, Gaia2 runs asynchronously, surfacing new failure modes that are invisible in static settings.</p></div></a><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/are/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/facebookresearch/meta-agents-research-environments target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://huggingface.co/datasets/meta-agents-research-environments/gaia2 target=_blank rel=noopener>Dataset</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://facebookresearch.github.io/meta-agents-research-environments/ target=_blank rel=noopener>Docs</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2509.17158v1 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://huggingface.co/spaces/meta-agents-research-environments/demo target=_blank rel=noopener>Demo</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://ai.meta.com/research/publications/are-scaling-up-agent-environments-and-evaluations/ target=_blank rel=noopener>Meta AI</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://huggingface.co/spaces/meta-agents-research-environments/leaderboard target=_blank rel=noopener>Leaderboard</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://huggingface.co/blog/gaia2 target=_blank rel=noopener>Post</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=9gw03JpKK4" target=_blank rel=noopener>OpenReview</a></div></div><div class=card-simple><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/kortvelesy/>Ryan Kortvelesy</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>International Conference on Machine Learning (ICML)</em></span></div><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/><img src=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/featured_hu9dca1e83ecb59c40dcc79a7f11d4d205_4216083_808x455_fit_q90_lanczos.gif class=article-banner alt="Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning" loading=lazy></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/>Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning</a></div><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/ class=summary-link><div class=article-style><p>We introduce Diversity Control (DiCo), a method able to control diversity to an exact value of a given metric by representing policies as the sum of a parameter-shared component and dynamically scaled per-agent components. By applying constraints directly to the policy architecture, DiCo leaves the learning objective unchanged, enabling its applicability to any actor-critic MARL algorithm. We theoretically prove that DiCo achieves the desired diversity, and we provide several experiments, both in cooperative and competitive tasks, that show how DiCo can be employed as a novel paradigm to increase performance and sample efficiency in MARL.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/Controlling-Behavioral-Diversity-in-Multi-Agent-Reinforcement-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/ControllingBehavioralDiversity target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://sites.google.com/view/dico-marl target=_blank rel=noopener>Website</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=qQjUgItPq4" target=_blank rel=noopener>OpenReview</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2405.15054 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/poster.pdf>Poster</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/ImcuXnmX43g target=_blank rel=noopener>Talk</a></div></div><div class=card-simple><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span>, <span><a href=/authors/vincent-moens/>Vincent Moens</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Journal of Machine Learning Research (JMLR)</em></span></div><a href=/publication/benchmarl/><img src=/publication/benchmarl/featured_hu61ea57729c9eea7664f9ac410fbef93f_1166554_808x455_fit_q90_lanczos.jpg class=article-banner alt="BenchMARL: Benchmarking Multi-Agent Reinforcement Learning" loading=lazy></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/benchmarl/>BenchMARL: Benchmarking Multi-Agent Reinforcement Learning</a></div><a href=/publication/benchmarl/ class=summary-link><div class=article-style><p>BenchMARL is a library for benchmarking Multi-Agent Reinforcement Learning (MARL) using TorchRL. BenchMARL allows to quickly compare different MARL algorithms, tasks, and models while being systematically grounded in its two core tenets: reproducibility and standardization.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/benchmarl/BenchMARL.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/benchmarl/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/facebookresearch/BenchMARL target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://benchmarl.readthedocs.io/ target=_blank rel=noopener>Docs</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://wandb.ai/matteobettini/benchmarl-public/reportlist target=_blank rel=noopener>Wandb Benchmarks</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=1tOIMgJf_VQ" target=_blank rel=noopener>Talk</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=mIb1uGeRJsg" target=_blank rel=noopener>Lecture</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2312.01472 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/benchmarl/poster.pdf>Poster</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=http://jmlr.org/papers/v25/23-1612.html target=_blank rel=noopener>JMLR</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://neurips.cc/virtual/2024/poster/98318 target=_blank rel=noopener>NeurIPS</a></div></div></div></div></div></section><section id=publications class="home-section wg-portfolio"><div class=home-section-bg></div><div class=container><div class="row justify-content-center"><div class="section-heading col-12 mb-3 text-center"><h1 class=mb-0>Publications</h1></div><div class=col-12><p>To find relevant content, try <a href=./publication/>searching publications</a> or filtering using the buttons below.</p><span class="d-none default-project-filter">*</span><div class=project-toolbar><div class=project-filters><div class=btn-toolbar><div class="btn-group flex-wrap"><a href=# data-filter=* class="btn btn-primary btn-lg active">All</a>
<a href=# data-filter=.js-id-Heterogeneity class="btn btn-primary btn-lg">Heterogeneity</a>
<a href=# data-filter=.js-id-Multi-Agent-Reinforcement-Learning class="btn btn-primary btn-lg">Multi-Agent Reinforcement Learning</a>
<a href=# data-filter=.js-id-Software-library class="btn btn-primary btn-lg">Software library</a>
<a href=# data-filter=.js-id-LLM-Agents class="btn btn-primary btn-lg">LLM Agents</a></div></div></div></div><div class="isotope projects-container row js-layout-row"><div class="col-12 isotope-item js-id-Software-library js-id-LLM-Agents"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/are/>ARE: Scaling Up Agent Environments and Evaluations</a></div><a href=/publication/are/ class=summary-link><div class=article-style>We introduce Meta Agents Research Environments (ARE), a research platform for scalable creation of environments, integration of synthetic or real applications, and execution of agentic orchestrations. We also propose Gaia2, a benchmark built in ARE and designed to measure general agent capabilities. Unlike prior benchmarks, Gaia2 runs asynchronously, surfacing new failure modes that are invisible in static settings.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/authors/pierre-andrews/>Pierre Andrews</a></span>, <span><a href=/authors/amine-benhalloum/>Amine Benhalloum</a></span>, <span><a href=/authors/gerard-moreno-torres-bertran/>Gerard Moreno-Torres Bertran</a></span>, <span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/amar-budhiraja/>Amar Budhiraja</a></span>, <span><a href=/authors/ricardo-silveira-cabral/>Ricardo Silveira Cabral</a></span>, <span><a href=/authors/virginie-do/>Virginie Do</a></span>, <span><a href=/authors/romain-froger/>Romain Froger</a></span>, <span><a href=/authors/emilien-garreau/>Emilien Garreau</a></span>, <span><a href=/authors/jean-baptiste-gaya/>Jean-Baptiste Gaya</a></span>, <span><a href=/authors/hugo-laurencon/>Hugo LaurenÃ§on</a></span>, <span><a href=/authors/maxime-lecanu/>Maxime Lecanu</a></span>, <span><a href=/authors/kunal-malkan/>Kunal Malkan</a></span>, <span><a href=/authors/dheeraj-mekala/>Dheeraj Mekala</a></span>, <span><a href=/authors/pierre-menard/>Pierre MÃ©nard</a></span>, <span><a href=/authors/gregoire-mialon/>GrÃ©goire Mialon</a></span>, <span><a href=/authors/ulyana-piterbarg/>Ulyana Piterbarg</a></span>, <span><a href=/authors/mikhail-plekhanov/>Mikhail Plekhanov</a></span>, <span><a href=/authors/mathieu-rita/>Mathieu Rita</a></span>, <span><a href=/authors/andrey-rusakov/>Andrey Rusakov</a></span>, <span><a href=/authors/thomas-scialom/>Thomas Scialom</a></span>, <span><a href=/authors/vladislav-vorotilov/>Vladislav Vorotilov</a></span>, <span><a href=/authors/mengjue-wang/>Mengjue Wang</a></span>, <span><a href=/authors/ian-yu/>Ian Yu</a></span></div><span class=article-date>2026</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>International Conference on Learning Representations (ICLR)</em> - <strong><em>Oral (top 2%)</em></strong></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/are/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/facebookresearch/meta-agents-research-environments target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://huggingface.co/datasets/meta-agents-research-environments/gaia2 target=_blank rel=noopener>Dataset</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://facebookresearch.github.io/meta-agents-research-environments/ target=_blank rel=noopener>Docs</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2509.17158v1 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://huggingface.co/spaces/meta-agents-research-environments/demo target=_blank rel=noopener>Demo</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://ai.meta.com/research/publications/are-scaling-up-agent-environments-and-evaluations/ target=_blank rel=noopener>Meta AI</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://huggingface.co/spaces/meta-agents-research-environments/leaderboard target=_blank rel=noopener>Leaderboard</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://huggingface.co/blog/gaia2 target=_blank rel=noopener>Post</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=9gw03JpKK4" target=_blank rel=noopener>OpenReview</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/are/><img src=/publication/are/compact_hub262ee4bb15642b1284724f1a6218afe_154991_300x0_resize_lanczos_3.png alt="ARE: Scaling Up Agent Environments and Evaluations" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Heterogeneity js-id-Multi-Agent-Reinforcement-Learning"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/hetenvdesign/>When Is Diversity Rewarded in Cooperative Multi-Agent Learning?</a></div><a href=/publication/hetenvdesign/ class=summary-link><div class=article-style>Focusing on multi-agent task allocation problems, our goal is to study the question: What kinds of objectives are best suited for heterogeneous teams? We first consider an instantaneous, non-spatial setting where the global reward is built by two generalized aggregation operators: an inner operator that maps the N agentsâ€™ effort allocations on individual tasks to a task score, and an outer operator that merges the M task scores into the global team reward. We prove that the curvature of these operators determines whether heterogeneity can increase reward, and that for broad reward families this collapses to a simple convexity test. Next, we study heterogeneity in multi-agent reinforcement learning (MARL) and introduce Heterogeneous Environment Design (HED), a gradient-based algorithm that optimizes the parameter space of underspecified MARL environments to find scenarios where heterogeneity is advantageous.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/authors/michael-amir/>Michael Amir</a><i class=author-notes data-toggle=tooltip title="Equal contribution">*</i></span>, <span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a><i class=author-notes data-toggle=tooltip title="Equal contribution">*</i></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2026</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>International Conference on Learning Representations (ICLR)</em></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/hetenvdesign/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/HetEnvDesign target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2506.09434 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=uJCGMBO6Qx" target=_blank rel=noopener>OpenReview</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/hetenvdesign/><img src=/publication/hetenvdesign/compact_hub6a6cfc3970b062cfd31c62679945bd0_732287_300x0_resize_lanczos_3.png alt="When Is Diversity Rewarded in Cooperative Multi-Agent Learning?" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Multi-Agent-Reinforcement-Learning js-id-Heterogeneity"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/phd-thesis/>Neural diversity in multi-agent learning</a></div><a href=/publication/phd-thesis/ class=summary-link><div class=article-style>This thesis presents a study of neural diversity in multi-agent systems, demonstrating its key, though previously ignored, role in collective learning. We introduce novel methods to simulate, enable, train, measure, and control neural diversity in multi-agent reinforcement learning. The results gathered show that neural diversity is fundamental for cooperation, exploration, and resilience, paving the way towards the understanding and development of collective artificial general intelligence.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span></div><span class=article-date>2025</span>
<span class=middot-divider></span>
<span class=pub-publication>PhD Thesis</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.repository.cam.ac.uk/handle/1810/388334 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/phd-thesis/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.repository.cam.ac.uk/handle/1810/388334 target=_blank rel=noopener>University of Cambridge</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/phd-thesis/><img src=/publication/phd-thesis/compact_hu2b68d0c9efbd39e4a551c3503166e592_1902566_300x0_resize_lanczos_3.png alt="Neural diversity in multi-agent learning" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Heterogeneity js-id-Multi-Agent-Reinforcement-Learning"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/the-impact-of-behavioral-diversity-in-multi-agent-reinforcement-learning/>The impact of behavioral diversity in multi-agent reinforcement learning</a></div><a href=/publication/the-impact-of-behavioral-diversity-in-multi-agent-reinforcement-learning/ class=summary-link><div class=article-style>In this work, we employ diversity measurement and control paradigms to study the impact of behavioral heterogeneity in several facets of multi-agent reinforcement learning. Through experiments in team play and other cooperative tasks, we show the emergence of unbiased behavioral roles that improve team outcomes; how behavioral diversity synergizes with morphological diversity; how diverse agents are more effective at finding cooperative solutions in sparse reward settings; and how behaviorally heterogeneous teams learn and retain latent skills to overcome repeated disruptions.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/kortvelesy/>Ryan Kortvelesy</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2025</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Preprint</em></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/the-impact-of-behavioral-diversity-in-multi-agent-reinforcement-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://assets-eu.researchsquare.com/files/rs-5589114/v1/7f7d08273ac335398f420416.mp4 target=_blank rel=noopener>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://assets-eu.researchsquare.com/files/rs-5589114/v1/ccbfa32bb60ebfc5abc662fd.mp4 target=_blank rel=noopener>Soccer trailer</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2412.16244 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://codeocean.com/capsule/4161071/tree/ target=_blank rel=noopener>Code Ocean</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/the-impact-of-behavioral-diversity-in-multi-agent-reinforcement-learning/><img src=/publication/the-impact-of-behavioral-diversity-in-multi-agent-reinforcement-learning/compact_hu1a5a1fe014a0590596af17ef77215666_33607400_300x0_resize_lanczos.gif alt="The impact of behavioral diversity in multi-agent reinforcement learning" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Heterogeneity js-id-Multi-Agent-Reinforcement-Learning"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/heterogeneous-teams/>Heterogeneous Teams</a></div><a href=/publication/heterogeneous-teams/ class=summary-link><div class=article-style>The aim of this chapter is to provide an overview of heterogeneous teams, from a robotics perspective.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/authors/prorok/>Amanda Prorok</a></span>, <span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Encyclopedia of Robotics</em></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/heterogeneous-teams/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://link.springer.com/referenceworkentry/10.1007/978-3-642-41610-1_230-1 target=_blank rel=noopener>Springer link</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/heterogeneous-teams/><img src=/publication/heterogeneous-teams/compact_hud59ed9e7a0b39e8d92b1aece9a7e9e9d_209553_300x0_resize_q100_lanczos.jpg alt="Heterogeneous Teams" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Multi-Agent-Reinforcement-Learning js-id-Heterogeneity"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/>Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning</a></div><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/ class=summary-link><div class=article-style>We introduce Diversity Control (DiCo), a method able to control diversity to an exact value of a given metric by representing policies as the sum of a parameter-shared component and dynamically scaled per-agent components. By applying constraints directly to the policy architecture, DiCo leaves the learning objective unchanged, enabling its applicability to any actor-critic MARL algorithm. We theoretically prove that DiCo achieves the desired diversity, and we provide several experiments, both in cooperative and competitive tasks, that show how DiCo can be employed as a novel paradigm to increase performance and sample efficiency in MARL.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/kortvelesy/>Ryan Kortvelesy</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>International Conference on Machine Learning (ICML)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/Controlling-Behavioral-Diversity-in-Multi-Agent-Reinforcement-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/ControllingBehavioralDiversity target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://sites.google.com/view/dico-marl target=_blank rel=noopener>Website</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=qQjUgItPq4" target=_blank rel=noopener>OpenReview</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2405.15054 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/poster.pdf>Poster</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/ImcuXnmX43g target=_blank rel=noopener>Talk</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/><img src=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/compact_hu9dca1e83ecb59c40dcc79a7f11d4d205_4216083_300x0_resize_lanczos.gif alt="Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Multi-Agent-Reinforcement-Learning"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/robomaster/>The Cambridge RoboMaster: An Agile Multi-Robot Research Platform</a></div><a href=/publication/robomaster/ class=summary-link><div class=article-style>This article introduces a tightly integrated hardware, control, and simulation software stack on a fleet of holonomic ground robot platforms. Our robots, a fleet of customised DJI Robomaster S1 vehicles, offer a balance between small robots that do not possess sufficient compute or actuation capabilities and larger robots that are unsuitable for indoor multi-robot tests.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/authors/blumenkamp/>Jan Blumenkamp</a></span>, <span><a href=/authors/shankar/>Ajay Shankar</a></span>, <span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/joshua-bird/>Joshua Bird</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Distributed Autonomous Robotic Systems (DARS)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/robomaster/robomaster.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/robomaster/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/cambridge-robomaster target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://proroklab.github.io/cambridge-robomaster/supplementary.html#vmas-deployment target=_blank rel=noopener>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://proroklab.github.io/cambridge-robomaster/ target=_blank rel=noopener>Docs</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2405.02198 target=_blank rel=noopener>arXiv</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/robomaster/><img src=/publication/robomaster/compact_hu46efff4e28ca506a88be1427516cbd21_2261186_300x0_resize_lanczos_3.png alt="The Cambridge RoboMaster: An Agile Multi-Robot Research Platform" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Multi-Agent-Reinforcement-Learning js-id-Software-library"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/benchmarl/>BenchMARL: Benchmarking Multi-Agent Reinforcement Learning</a></div><a href=/publication/benchmarl/ class=summary-link><div class=article-style>BenchMARL is a library for benchmarking Multi-Agent Reinforcement Learning (MARL) using TorchRL. BenchMARL allows to quickly compare different MARL algorithms, tasks, and models while being systematically grounded in its two core tenets: reproducibility and standardization.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span>, <span><a href=/authors/vincent-moens/>Vincent Moens</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Journal of Machine Learning Research (JMLR)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/benchmarl/BenchMARL.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/benchmarl/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/facebookresearch/BenchMARL target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://benchmarl.readthedocs.io/ target=_blank rel=noopener>Docs</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://wandb.ai/matteobettini/benchmarl-public/reportlist target=_blank rel=noopener>Wandb Benchmarks</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=1tOIMgJf_VQ" target=_blank rel=noopener>Talk</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=mIb1uGeRJsg" target=_blank rel=noopener>Lecture</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2312.01472 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/benchmarl/poster.pdf>Poster</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=http://jmlr.org/papers/v25/23-1612.html target=_blank rel=noopener>JMLR</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://neurips.cc/virtual/2024/poster/98318 target=_blank rel=noopener>NeurIPS</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/benchmarl/><img src=/publication/benchmarl/compact_hu0971da7d7467813a850f11c8b39be638_3051643_300x0_resize_lanczos_3.png alt="BenchMARL: Benchmarking Multi-Agent Reinforcement Learning" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Multi-Agent-Reinforcement-Learning js-id-Software-library"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/>TorchRL: A data-driven decision-making library for PyTorch</a></div><a href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/ class=summary-link><div class=article-style>We propose TorchRL, a generalistic control library for PyTorch that provides well-integrated, yet standalone components. With a versatile and robust primitive design, TorchRL facilitates streamlined algorithm development across the many branches of Reinforcement Learning (RL) and control. We introduce a new PyTorch primitive, TensorDict, as a flexible data carrier that empowers the integration of the libraryâ€™s components while preserving their modularity. TorchRL fosters long-term support and is publicly available on GitHub for greater reproducibility and collaboration within the research community.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/authors/albert-bou/>Albert Bou</a></span>, <span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/sebastian-dittert/>Sebastian Dittert</a></span>, <span><a href=/authors/vikash-kumar/>Vikash Kumar</a></span>, <span><a href=/authors/shagun-sodhani/>Shagun Sodhani</a></span>, <span><a href=/authors/xiaomeng-yang/>Xiaomeng Yang</a></span>, <span><a href=/authors/gianni-de-fabritiis/>Gianni De Fabritiis</a></span>, <span><a href=/authors/vincent-moens/>Vincent Moens</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>International Conference on Learning Representations (ICLR)</em> - <strong><em>Spotlight (top 5%)</em></strong></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/TorchRL-A-data-driven-decision-making-library-for-PyTorch.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/pytorch/rl target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://pytorch.org/rl/ target=_blank rel=noopener>Documentation</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2306.00577 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=QxItoEAVMb" target=_blank rel=noopener>OpenReview</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/poster.pdf>Poster</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/><img src=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/compact_hu903fd55680461821a9b538ed6f8cf6de_77481_300x0_resize_lanczos_3.png alt="TorchRL: A data-driven decision-making library for PyTorch" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Heterogeneity js-id-Multi-Agent-Reinforcement-Learning"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/>System Neural Diversity: Measuring Behavioral Heterogeneity in Multi-Agent Learning</a></div><a href=/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/ class=summary-link><div class=article-style>In this paper, we introduce System Neural Diversity (SND): a measure of behavioral heterogeneity for multi-agent systems where agents have stochastic policies. We discuss and prove its theoretical properties, and compare it with alternate, state-of-the-art behavioral diversity metrics used in cross-disciplinary domains. Through simulations of a variety of multi-agent tasks, we show how our metric constitutes an important diagnostic tool to analyze latent properties of behavioral heterogeneity.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/shankar/>Ajay Shankar</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2023</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Journal of Machine Learning Research (JMLR)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/System-Neural-Diversity-Measuring-Behavioral-Heterogeneity-in-Multi-Agent-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/HetGPPO target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=http://jmlr.org/papers/v26/24-1477.html target=_blank rel=noopener>JMLR</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2305.02128 target=_blank rel=noopener>arXiv</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/><img src=/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/compact_hu1e3587a73e760af3ad1dedea38e4387a_749078_300x0_resize_lanczos_3.png alt="System Neural Diversity: Measuring Behavioral Heterogeneity in Multi-Agent Learning" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Heterogeneity js-id-Multi-Agent-Reinforcement-Learning"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/heterogeneous-multi-robot-reinforcement-learning/>Heterogeneous Multi-Robot Reinforcement Learning</a></div><a href=/publication/heterogeneous-multi-robot-reinforcement-learning/ class=summary-link><div class=article-style>In this paper, we crystallize the role of heterogeneity in MARL policies. We introduce Heterogeneous Graph Neural Network Proximal Policy Optimization (HetGPPO), a paradigm for training heterogeneous MARL policies that leverages a Graph Neural Network for differentiable inter-agent communication. HetGPPO allows communicating agents to learn heterogeneous behaviors while enabling fully decentralized training in partially observable environments. Through simulations and real-world experiments, we show that: (i) when homogeneous methods fail due to strong heterogeneous requirements, HetGPPO succeeds, and, (ii) when homogeneous methods are able to learn apparently heterogeneous behaviors, HetGPPO achieves higher resilience to both training and deployment noise.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/shankar/>Ajay Shankar</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2023</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Autonomous Agents and Multiagent Systems (AAMAS)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/heterogeneous-multi-robot-reinforcement-learning/Heterogeneous-Multi-Robot-Reinforcement-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/heterogeneous-multi-robot-reinforcement-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/HetGPPO target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=J81IVQEy-zw" target=_blank rel=noopener>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2301.07137 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=a4md0es3kuo" target=_blank rel=noopener>Talk</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/heterogeneous-multi-robot-reinforcement-learning/poster.pdf>Poster</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/heterogeneous-multi-robot-reinforcement-learning/><img src=/publication/heterogeneous-multi-robot-reinforcement-learning/compact_hu1234d6e5d8e0fe29abec561068287070_2300259_300x0_resize_lanczos_3.png alt="Heterogeneous Multi-Robot Reinforcement Learning" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Software-library"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/>POPGym: Benchmarking Partially Observable Reinforcement Learning</a></div><a href=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/ class=summary-link><div class=article-style>We introduce Partially Observable Process Gym (POPGym), a two-part library containing (1) a diverse collection of 14 partially observable environments, each with multiple difficulties and (2) implementations of 13 memory model baselines â€“ the most in a single RL library. Using POPGym, we execute the largest comparison across RL memory models to date.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/authors/morad/>Steven Morad</a></span>, <span><a href=/authors/kortvelesy/>Ryan Kortvelesy</a></span>, <span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/stephan-liwicki/>Stephan Liwicki</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2023</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>International Conference on Learning Representations (ICLR)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/POPGym-Benchmarking-Partially-Observable-Reinforcement-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/smorad/popgym target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2303.01859 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=chDrutUTs0K" target=_blank rel=noopener>OpenReview</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/poster.png>Poster</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/><img src=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/compact_hu08087b80d13a316aaceae06d8ed23885_323361_300x0_resize_lanczos_3.png alt="POPGym: Benchmarking Partially Observable Reinforcement Learning" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Multi-Agent-Reinforcement-Learning js-id-Software-library"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/>VMAS: A Vectorized Multi-Agent Simulator for Collective Robot Learning</a></div><a href=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/ class=summary-link><div class=article-style>In this paper, we introduce the Vectorized Multi-Agent Simulator (VMAS). VMAS is an open-source framework designed for efficient MARL benchmarking. It comprises a vectorized 2D physics engine written in PyTorch and a set of twelve challenging multi-robot scenarios. Additional scenarios can be implemented through a simple and modular interface. We demonstrate how vectorization enables parallel simulation on accelerated hardware without added complexity.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/kortvelesy/>Ryan Kortvelesy</a></span>, <span><a href=/authors/blumenkamp/>Jan Blumenkamp</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2022</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Distributed Autonomous Robotic Systems (DARS)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/VMAS-A-Vectorized-Multi-Agent-Simulator-for-Collective-Robot-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/VectorizedMultiAgentSimulator target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=aaDRYfiesAY&t=1s" target=_blank rel=noopener>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/boViBY7Woqg target=_blank rel=noopener>Talk</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=mIb1uGeRJsg" target=_blank rel=noopener>Lecture</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2207.03530 target=_blank rel=noopener>arXiv</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/><img src=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/compact_hua4f5b9e0add8e9e8c3203a579e61fbd6_755644_300x0_resize_lanczos_3.png alt="VMAS: A Vectorized Multi-Agent Simulator for Collective Robot Learning" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item js-id-Transport-Network-Design"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/on-the-properties-of-path-additions-for-traffic-routing/>On the Properties of Path Additions for Traffic Routing</a></div><a href=/publication/on-the-properties-of-path-additions-for-traffic-routing/ class=summary-link><div class=article-style>In this paper, we investigate the impact of path additions to transport networks with optimised traffic routing. In particular, we study the behaviour of total travel time, and consider both self-interested routing paradigms, such as User Equilibrium (UE) routing, as well as cooperative paradigms, such as classic Multi-Commodity (MC) network flow and System Optimal (SO) routing. This work aims to provide an analysis and categorization of the properties of objective functions for transport network design, with the purpose of informing algorithm (and also network) designers. Among our results, we prove, via counterexample, that total travel time, under both cooperative and self-interested routing, is not supermodular with respect to path additions.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2022</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>IEEE International Conference on Intelligent Transportation Systems (ITSC) Workshop on Co-Design and Coordination of Future Mobility Systems</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/on-the-properties-of-path-additions-for-traffic-routing/On-the-properties-of-path-additions-for-traffic-routing.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/on-the-properties-of-path-additions-for-traffic-routing/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/matteobettini/Traffic-Assignment-Frank-Wolfe-2021 target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2207.04505 target=_blank rel=noopener>arXiv</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/on-the-properties-of-path-additions-for-traffic-routing/><img src=/publication/on-the-properties-of-path-additions-for-traffic-routing/compact_hub80e700c5eadfc1ac79e44fc5dc02fe5_506162_300x0_resize_lanczos_3.png alt="On the Properties of Path Additions for Traffic Routing" loading=lazy></a></div></div></div></div><div class="col-12 isotope-item"><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/mphil-thesis/>Transport network design for vehicle routing: results on path addition and capacity reduction</a></div><a href=/publication/mphil-thesis/ class=summary-link><div class=article-style>In this thesis, we investigate the problem of optimising the transportation network for AVs both from a theoretical and from a practical perspective. In the first part, we investigate the properties of adding paths to a network and we prove that path additions to transport networks, where AVs are routed, are not supermodular in travel time, extending the seminal result of Braessâ€™ paradox. In the second part, we formulate two network design problems for self-interested AVs. We present the problem of optimising transport networks via path additions and a novel problem design where self-interested users are guided towards optimal paths through the reduction of road capacities. Through capacity reductions, we achieve significant total travel time improvements on six real-world transport networks: Anaheim (USA), Barcelona (Spain), Chicago (USA), Eastern Massachusetts (USA), Sioux Falls (USA), and Winnipeg (Canada). For instance, we improve the Chicago network by up to 7%, saving more than 487 hours of total travel time per traffic hour.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span></div><span class=article-date>2021</span>
<span class=middot-divider></span>
<span class=pub-publication>MPhil Thesis</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/mphil-thesis/mphil-thesis.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/mphil-thesis/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/matteobettini/Traffic-Assignment-Frank-Wolfe-2021 target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/FPbyjnwUizQ target=_blank rel=noopener>Video</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/mphil-thesis/><img src=/publication/mphil-thesis/compact_hu9662cb3a79fd0a9108ceaf2b615f454b_168090_300x0_resize_lanczos_3.png alt="Transport network design for vehicle routing: results on path addition and capacity reduction" loading=lazy></a></div></div></div></div></div></div></div></div></section><section id=contact class="home-section wg-contact"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Contact</h1></div><div class="col-12 col-lg-8"><ul class=fa-ul><li><i class="fa-li fas fa-envelope fa-2x" aria-hidden=true></i>
<span id=person-email><a href=mailto:mb2389@cl.cam.ac.uk>mb2389@cl.cam.ac.uk</a></span></li><li><i class="fa-li ai ai-google-scholar fa-2x" aria-hidden=true></i>
<a href="https://scholar.google.com/citations?user=hcvR_W0AAAAJ" target=_blank rel=noopener>Google Scholar</a></li><li><i class="fa-li ai ai-semantic-scholar fa-2x" aria-hidden=true></i>
<a href=https://www.semanticscholar.org/author/Matteo-Bettini/2153781474 target=_blank rel=noopener>Semantic Scholar</a></li><li><i class="fa-li fab fa-github fa-2x" aria-hidden=true></i>
<a href=https://github.com/matteobettini target=_blank rel=noopener>GitHub</a></li><li><i class="fa-li fab fa-linkedin fa-2x" aria-hidden=true></i>
<a href=https://www.linkedin.com/in/bettinimatteo/ target=_blank rel=noopener>Linkedin</a></li><li><i class="fa-li fab fa-youtube fa-2x" aria-hidden=true></i>
<a href=http://www.youtube.com/@matteobettini1871 target=_blank rel=noopener>YouTube</a></li></ul></div></div></div></section></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>View <a href=https://github.com/matteobettini/professional_website target=_blank rel=noopener>source</a>.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script>
<script src=/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script>
<script src=/en/js/wowchemy.min.26bc5a5b73c468c9e767656a378ac5e3.js></script>
<script async defer src=https://buttons.github.io/buttons.js></script></body></html>