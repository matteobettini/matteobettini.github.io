[{"authors":null,"categories":null,"content":"Hello! üëã I am Matteo, a PhD student in the Prorok Lab at the University of Cambridge. With my supervisor, Amanda Prorok, I study resilience and heterogeneity in multi-agent and multi-robot systems. For my research, I employ techniques from the fields of Multi-Agent Reinforcement Learning and Graph Neural Networks.\nPrior to my PhD, I investigated the problem of transport network design for multi-agent routing.\nDownload my CV.\n","date":1704067200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1704067200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://matteobettini.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Hello! üëã I am Matteo, a PhD student in the Prorok Lab at the University of Cambridge. With my supervisor, Amanda Prorok, I study resilience and heterogeneity in multi-agent and multi-robot systems.","tags":null,"title":"Matteo Bettini","type":"authors"},{"authors":null,"categories":null,"content":"Bio My research focuses on multi-agent and multi-robot systems. Our mission is to find new ways of coordinating artificially intelligent agents (e.g., robots, vehicles, machines) to achieve common goals in shared physical and virtual spaces.\n","date":1701648e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1701648e3,"objectID":"19a9369be31a010df83b684612118d3e","permalink":"https://matteobettini.github.io/authors/prorok/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/prorok/","section":"authors","summary":"Bio My research focuses on multi-agent and multi-robot systems. Our mission is to find new ways of coordinating artificially intelligent agents (e.g., robots, vehicles, machines) to achieve common goals in shared physical and virtual spaces.","tags":null,"title":"Amanda Prorok","type":"authors"},{"authors":null,"categories":null,"content":"Bio Ajay‚Äôs research is that of a full-stack roboticist ‚Äì with a focus on robust, optimal, and agile control + planning for various robots and robotic teams. Current focus is on scalable and learnt multi-robot coordination.\n","date":1680307200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1680307200,"objectID":"48f97eacc0dfe9001fbf7d4adf7e3f50","permalink":"https://matteobettini.github.io/authors/shankar/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/shankar/","section":"authors","summary":"Bio Ajay‚Äôs research is that of a full-stack roboticist ‚Äì with a focus on robust, optimal, and agile control + planning for various robots and robotic teams. Current focus is on scalable and learnt multi-robot coordination.","tags":null,"title":"Ajay Shankar","type":"authors"},{"authors":null,"categories":null,"content":"Bio Ryan‚Äôs work focuses on multi-agent reinforcement learning. He is interested in the credit assignment problem, new graph neural network architectures and explainability (applying symbolic regression to multi-agent systems).\n","date":1672790400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1672790400,"objectID":"d818a342934a25fd08b803493165c6a5","permalink":"https://matteobettini.github.io/authors/kortvelesy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/kortvelesy/","section":"authors","summary":"Bio Ryan‚Äôs work focuses on multi-agent reinforcement learning. He is interested in the credit assignment problem, new graph neural network architectures and explainability (applying symbolic regression to multi-agent systems).","tags":null,"title":"Ryan Kortvelesy","type":"authors"},{"authors":null,"categories":null,"content":"Bio Steven studies how long-term memory can improve decision making in reinforcement learning. He focuses on arranging collections of memories into graph structures, which he queries using graph neural networks. His research aims to improve the reasoning capabilities of robots, allowing them to solve human-level tasks and learn from and correct mistakes in real-time.\n","date":1672790400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1672790400,"objectID":"efd495911eaf49f08948ed0d46d0f62a","permalink":"https://matteobettini.github.io/authors/morad/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/morad/","section":"authors","summary":"Bio Steven studies how long-term memory can improve decision making in reinforcement learning. He focuses on arranging collections of memories into graph structures, which he queries using graph neural networks. His research aims to improve the reasoning capabilities of robots, allowing them to solve human-level tasks and learn from and correct mistakes in real-time.","tags":null,"title":"Steven Morad","type":"authors"},{"authors":null,"categories":null,"content":"Bio Jan‚Äôs research is about transferring Multi-Agent control policies trained in simulation to the real world (sim-to-real transfer), using Multi-Agent Reinforcement Learning and Graph Neural Networks. He is also interested in interpretability, resilience and robustness of such control policies, particularly in the context of real-world systems.\n","date":1657497600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1657497600,"objectID":"00443489be71f03990762ebf3232d59f","permalink":"https://matteobettini.github.io/authors/blumenkamp/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/blumenkamp/","section":"authors","summary":"Bio Jan‚Äôs research is about transferring Multi-Agent control policies trained in simulation to the real world (sim-to-real transfer), using Multi-Agent Reinforcement Learning and Graph Neural Networks. He is also interested in interpretability, resilience and robustness of such control policies, particularly in the context of real-world systems.","tags":null,"title":"Jan Blumenkamp","type":"authors"},{"authors":null,"categories":null,"content":" Table of Contents What you will learn Program overview Courses in this program Meet your instructor FAQs What you will learn Fundamental Python programming skills Statistical concepts and how to apply them in practice Gain experience with the Scikit, including data visualization with Plotly and data wrangling with Pandas Program overview The demand for skilled data science practitioners is rapidly growing. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi.\nCourses in this program Python basics Build a foundation in Python. Visualization Learn how to visualize data with Plotly. Statistics Introduction to statistics for data science. Meet your instructor Matteo Bettini FAQs Are there prerequisites? There are no prerequisites for the first course.\nHow often do the courses run? Continuously, at your own pace.\nBegin the course ","date":1611446400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1611446400,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://matteobettini.github.io/courses/example/","publishdate":"2021-01-24T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"An example of using Wowchemy's Book layout for publishing online courses.","tags":null,"title":"üìä Learn Data Science","type":"book"},{"authors":null,"categories":null,"content":"Build a foundation in Python.\n1-2 hours per week, for 8 weeks\nLearn Quiz What is the difference between lists and tuples? Lists\nLists are mutable - they can be changed Slower than tuples Syntax: a_list = [1, 2.0, 'Hello world'] Tuples\nTuples are immutable - they can\u0026rsquo;t be changed Tuples are faster than lists Syntax: a_tuple = (1, 2.0, 'Hello world') Is Python case-sensitive? Yes\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"17a31b92253d299002593b7491eedeea","permalink":"https://matteobettini.github.io/courses/example/python/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/python/","section":"courses","summary":"Build a foundation in Python.\n","tags":null,"title":"Python basics","type":"book"},{"authors":null,"categories":null,"content":"Learn how to visualize data with Plotly.\n1-2 hours per week, for 8 weeks\nLearn Quiz When is a heatmap useful? Lorem ipsum dolor sit amet, consectetur adipiscing elit.\nWrite Plotly code to render a bar chart import plotly.express as px data_canada = px.data.gapminder().query(\u0026quot;country == 'Canada'\u0026quot;) fig = px.bar(data_canada, x='year', y='pop') fig.show() ","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"1b341b3479c8c6b1f807553b77e21b7c","permalink":"https://matteobettini.github.io/courses/example/visualization/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/visualization/","section":"courses","summary":"Learn how to visualize data with Plotly.\n","tags":null,"title":"Visualization","type":"book"},{"authors":null,"categories":null,"content":"Introduction to statistics for data science.\n1-2 hours per week, for 8 weeks\nLearn The general form of the normal probability density function is:\n$$ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi} } e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2} $$\nThe parameter $\\mu$ is the mean or expectation of the distribution. $\\sigma$ is its standard deviation. The variance of the distribution is $\\sigma^{2}$. Quiz What is the parameter $\\mu$? The parameter $\\mu$ is the mean or expectation of the distribution.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"6f4078728d71b1b791d39f218bf2bdb1","permalink":"https://matteobettini.github.io/courses/example/stats/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/stats/","section":"courses","summary":"Introduction to statistics for data science.\n","tags":null,"title":"Statistics","type":"book"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://matteobettini.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Albert Bou","Matteo Bettini","Sebastian Dittert","Vikash Kumar","Shagun Sodhani","Xiaomeng Yang","Gianni De Fabritiis","Vincent Moens"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"f017ec0d8cbb76fe8ad90d5424150aec","permalink":"https://matteobettini.github.io/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/","section":"publication","summary":"We propose TorchRL, a generalistic control library for PyTorch that provides well-integrated, yet standalone components. With a versatile and robust primitive design, TorchRL facilitates streamlined algorithm development across the many branches of Reinforcement Learning (RL) and control. We introduce a new PyTorch primitive, TensorDict, as a flexible data carrier that empowers the integration of the library‚Äôs components while preserving their modularity. TorchRL fosters long-term support and is publicly available on GitHub for greater reproducibility and collaboration within the research community.","tags":["Multi-Agent Reinforcement Learning"],"title":"TorchRL: A data-driven decision-making library for PyTorch","type":"publication"},{"authors":["Matteo Bettini","Amanda Prorok","Vincent Moens"],"categories":null,"content":"","date":1701648e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701648e3,"objectID":"b23912fa2721d7bfcfe504829f0a15c8","permalink":"https://matteobettini.github.io/publication/benchmarl/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/benchmarl/","section":"publication","summary":"BenchMARL is a library for benchmarking Multi-Agent Reinforcement Learning (MARL) using TorchRL. BenchMARL allows to quickly compare different MARL algorithms, tasks, and models while being systematically grounded in its two core tenets\u0026#58; reproducibility and standardization.","tags":["Multi-Agent Reinforcement Learning"],"title":"BenchMARL: Benchmarking Multi-Agent Reinforcement Learning","type":"publication"},{"authors":["Matteo Bettini","Ajay Shankar","Amanda Prorok"],"categories":null,"content":"","date":1680307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680307200,"objectID":"638b58022b76995c06335d6d8289650b","permalink":"https://matteobettini.github.io/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/","section":"publication","summary":"In this paper, we introduce System Neural Diversity (SND)\u0026#58; a measure of behavioral heterogeneity for multi-agent systems where agents have stochastic policies. We discuss and prove its theoretical properties, and compare it with alternate, state-of-the-art behavioral diversity metrics used in cross-disciplinary domains. Through simulations of a variety of multi-agent tasks, we show how our metric constitutes an important diagnostic tool to analyze latent properties of behavioral heterogeneity.","tags":["Heterogeneity","Multi-Agent Reinforcement Learning"],"title":"System Neural Diversity: Measuring Behavioral Heterogeneity in Multi-Agent Learning","type":"publication"},{"authors":["Matteo Bettini","Ajay Shankar","Amanda Prorok"],"categories":null,"content":"","date":1672876800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672876800,"objectID":"96353ba7663707433000bbe313b6614c","permalink":"https://matteobettini.github.io/publication/heterogeneous-multi-robot-reinforcement-learning/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/heterogeneous-multi-robot-reinforcement-learning/","section":"publication","summary":"In this paper, we crystallize the role of heterogeneity in MARL policies. We introduce Heterogeneous Graph Neural Network Proximal Policy Optimization (HetGPPO), a paradigm for training heterogeneous MARL policies that leverages a Graph Neural Network for differentiable inter-agent communication. HetGPPO allows communicating agents to learn heterogeneous behaviors while enabling fully decentralized training in partially observable environments. Through simulations and real-world experiments, we show that\u0026#58; (i) when homogeneous methods fail due to strong heterogeneous requirements, HetGPPO succeeds, and, (ii) when homogeneous methods are able to learn apparently heterogeneous behaviors, HetGPPO achieves higher resilience to both training and deployment noise.","tags":["Heterogeneity","Multi-Agent Reinforcement Learning"],"title":"Heterogeneous Multi-Robot Reinforcement Learning","type":"publication"},{"authors":["Steven Morad","Ryan Kortvelesy","Matteo Bettini","Stephan Liwicki","Amanda Prorok"],"categories":null,"content":"","date":1672790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672790400,"objectID":"ac7347f3a5d5d0c3c93c5e41b44ebe3e","permalink":"https://matteobettini.github.io/publication/popgym-benchmarking-partially-observable-reinforcement-learning/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/popgym-benchmarking-partially-observable-reinforcement-learning/","section":"publication","summary":"We introduce Partially Observable Process Gym (POPGym), a two-part library containing (1) a diverse collection of 14 partially observable environments, each with multiple difficulties and (2) implementations of 13 memory model baselines ‚Äì the most in a single RL library. Using POPGym, we execute the largest comparison across RL memory models to date.","tags":null,"title":"POPGym: Benchmarking Partially Observable Reinforcement Learning","type":"publication"},{"authors":["Matteo Bettini","Ryan Kortvelesy","Jan Blumenkamp","Amanda Prorok"],"categories":null,"content":"Scenarios Multi-robot scenarios introduced in VMAS. Robots (blue shapes) interact among each other and with landmarks (green, red, and black shapes) to solve a task. Video ","date":1657497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657497600,"objectID":"5726f0fe709cafafe12ec55b0f739fc4","permalink":"https://matteobettini.github.io/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/","section":"publication","summary":"In this paper, we introduce the Vectorized Multi-Agent Simulator (VMAS). VMAS is an open-source framework designed for efficient MARL benchmarking. It comprises a vectorized 2D physics engine written in PyTorch and a set of twelve challenging multi-robot scenarios. Additional scenarios can be implemented through a simple and modular interface. We demonstrate how vectorization enables parallel simulation on accelerated hardware without added complexity.","tags":["Multi-Agent Reinforcement Learning"],"title":"VMAS: A Vectorized Multi-Agent Simulator for Collective Robot Learning","type":"publication"},{"authors":["Matteo Bettini","Amanda Prorok"],"categories":null,"content":"","date":1644105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644105600,"objectID":"74794d8f47b6c129c2f2dc3c0e3e2ebd","permalink":"https://matteobettini.github.io/publication/on-the-properties-of-path-additions-for-traffic-routing/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/on-the-properties-of-path-additions-for-traffic-routing/","section":"publication","summary":"In this paper, we investigate the impact of path additions to transport networks with optimised traffic routing. In particular, we study the behaviour of total travel time, and consider both self-interested routing paradigms, such as User Equilibrium (UE) routing, as well as cooperative paradigms, such as classic Multi-Commodity (MC) network flow and System Optimal (SO) routing. This work aims to provide an analysis and categorization of the properties of objective functions for transport network design, with the purpose of informing algorithm (and also network) designers. Among our results, we prove, via counterexample, that total travel time, under both cooperative and self-interested routing, is not supermodular with respect to path additions.","tags":["Transport Network Design"],"title":"On the Properties of Path Additions for Traffic Routing","type":"publication"},{"authors":["Matteo Bettini"],"categories":null,"content":" TL;DR:\nWe introduce BenchMARL, a training library for benchmarking MARL algorithms, tasks, and models backed by TorchRL. BenchMARL already contains a variety of SOTA algorithms and tasks. BenchMARL is grounded by its core tenets: standardization and reproducibility What is BenchMARL üßê? BenchMARL is a Multi-Agent Reinforcement Learning (MARL) training library created to enable reproducibility and benchmarking across different MARL algorithms and environments. Its mission is to present a standardized interface that allows easy integration of new algorithms and environments to provide a fair comparison with existing solutions. BenchMARL uses TorchRL as its backend, which grants it high performance and state-of-the-art implementations. It also uses hydra for flexible and modular configuration, and its data reporting is compatible with marl-eval for standardised and statistically strong evaluations.\nBenchMARL core design tenets are:\nReproducibility through systematical grounding and standardization of configuration Standardised and statistically-strong plotting and reporting Experiments that are independent of the algorithm, environment, and model choices Breadth over the MARL ecosystem Easy implementation of new algorithms, environments, and models Leveraging the know-how and infrastructure of TorchRL, without reinventing the wheel Why would I BenchMARL ü§î? Why would you BenchMARL, I see you ask. Well, you can BenchMARL to compare different algorithms, environments, models, to check how your new research compares to existing ones, or if you just want to approach the domain and want to easily take a picture of the landscape.\nWhy does it exist? We created it because, compared to other ML domains, RL has always been more fragmented in terms of shared community standards, tools, and interfaces. In MARL, this problem is even more evident, with new libraries being frequently introduced that focus on specific algorithms, environments, or models. Furthermore, these libraries often implement components from scratch, without leveraging the know-how of the single-agent RL community. In fact, the great majority of components used in MARL is shared with single-agent RL (e.g., losses like MAPPO, models, probability distributions, replay buffers, and much more).\nThis fragmentation of the domain has led to a reproducibility crisis, recently highlighted in a NeurIPS paper 1. While authors in 1 propose a set of tools for statistically-strong results\u0026rsquo; reporting, there is still the need for a standardized library to run such benchmarks. This is where BenchMARL comes in. Its mission is to provide a benchmarking tool for MARL, leveraging the components of TorchRL for a solid RL backend.\nHow do I use it? Command line Simple, to run an experiment from the command line do:\npython benchmarl/run.py algorithm=mappo task=vmas/balance to run multiple experiments, a benchmark you can do:\npython benchmarl/run.py -m algorithm=mappo,qmix,masac task=vmas/balance,vmas/sampling seed=0,1 Multirun has many launchers supported in the backend. The default implementation for hydra multirun is sequential, but parallel and slurm launchers are also available.\nScript Run an experiment:\nexperiment = Experiment( task=VmasTask.BALANCE.get_from_yaml(), algorithm_config=MappoConfig.get_from_yaml(), model_config=MlpConfig.get_from_yaml(), critic_model_config=MlpConfig.get_from_yaml(), seed=0, config=ExperimentConfig.get_from_yaml(), ) experiment.run() Run a benchmark:\nbenchmark = Benchmark( algorithm_configs=[ MappoConfig.get_from_yaml(), QmixConfig.get_from_yaml(), MasacConfig.get_from_yaml(), ], tasks=[ VmasTask.BALANCE.get_from_yaml(), VmasTask.SAMPLING.get_from_yaml(), ], seeds={0, 1}, experiment_config=ExperimentConfig.get_from_yaml(), model_config=MlpConfig.get_from_yaml(), critic_model_config=MlpConfig.get_from_yaml(), ) benchmark.run_sequential() Components The goal of BenchMARL is to bring different MARL environments and algorithms under the same interfaces to enable fair and reproducible comparison and benchmarking. BenchMARL is a full-pipline unified training library with the goal of enabling users to run any comparison they want across our algorithms and tasks in just one line of code. To achieve this, BenchMARL interconnects components from TorchRL, which provides an efficient and reliable backend.\nThe library has a default configuration for each of its components. While parts of this configuration are supposed to be changed (for example experiment configurations), other parts (such as tasks) should not be changed to allow for reproducibility. To aid in this, each version of BenchMARL is paired to a default configuration.\nLet\u0026rsquo;s now introduce each component in the library.\nExperiment. An experiment is a training run in which an algorithm, a task, and a model are fixed. Experiments are configured by passing these values alongside a seed and the experiment hyperparameters. The experiment hyperparameters cover both on-policy and off-policy algorithms, discrete and continuous actions, and probabilistic and deterministic policies (as they are agnostic of the algorithm or task used). An experiment can be launched from the command line or from a script.\nBenchmark. In the library we call benchmark a collection of experiments that can vary in tasks, algorithm, or model. A benchmark shares the same experiment configuration across all of its experiments. Benchmarks allow to compare different MARL components in a standardized way. A benchmark can be launched from the command line or from a script.\nAlgorithms. Algorithms are an ensemble of components (e.g., losss, replay buffer) which determine the training strategy. Here is a table with the currently implemented algorithms in BenchMARL.\nName On/Off policy Actor-critic Full-observability in critic Action compatibility Probabilistic actor MAPPO On Yes Yes Continuous + Discrete Yes IPPO On Yes No Continuous + Discrete Yes MADDPG Off Yes Yes Continuous No IDDPG Off Yes No Continuous No MASAC Off Yes Yes Continuous + Discrete Yes ISAC Off Yes No Continuous + Discrete Yes QMIX Off No NA Discrete No VDN Off No NA Discrete No IQL Off No NA Discrete No Tasks. Tasks are scenarios from a specific environment which constitute the MARL challenge to solve. They differ based on many aspects, here is a table with the current environments in BenchMARL\nEnvironment Tasks Cooperation Global state Reward function Action space Vectorized VMAS 5 Cooperative + Competitive No Shared + Independent + Global Continuous + Discrete Yes SMACv2 15 Cooperative Yes Global Discrete No MPE 8 Cooperative + Competitive Yes Shared + Independent Continuous + Discrete No SISL 2 Cooperative No Shared Continuous No BenchMARL uses the TorchRL MARL API for grouping agents. In competitive environments like MPE, for example, teams will be in different groups. Each group has its own loss, models, buffers, and so on. Parameter sharing options refer to sharing within the group. See the example on creating a custom algorithm for more info.\nModels. Models are neural networks used to process data. They can be used as actors (policies) or, when requested, as critics. We provide a set of base models (layers) and a SequenceModel to concatenate different layers. All the models can be used with or without parameter sharing within an agent group. Here is a table of the models implemented in BenchMARL\nName Decentralized Centralized with local inputs Centralized with global input MLP Yes Yes Yes And the ones that are work in progress\nName Decentralized Centralized with local inputs Centralized with global input GNN Yes Yes No CNN Yes Yes Yes Features BenchMARL has many features. In this section we will dive deep in the features that correspond to our core design tenets, but there are many more cool nuggets here and there, such as:\nA test CI with integration and training test routines that are run for all simulators and algorithms Integration in the official TorchRL ecosystem for dedicated support Experiment checkpointing and restoring using torch Experiment logging compatible with many loggers (wandb, csv, mflow, tensorboard). The wandb logger is fully compatible with experiment restoring and will automatically resume the run of the loaded experiment. In the following we illustrate the features which are core to our tenets.\nFine-tuned public benchmarks In the fine_tuned folder we are collecting some tested hyperparameters for specific environments to enable users to bootstrap their benchmarking. You can just run the scripts in this folder to automatically use the proposed hyperparameters.\nWe will tune benchmarks for you and publish the config and benchmarking plots on Wandb publicly\nCurrently available ones are:\nVVMAS: In the following, we report a table of the results:\nEnvironment\nSample efficiency curves (all tasks)\nPerformance profile\nAggregate scores\nVMAS Reporting and plotting Reporting and plotting is compatible with marl-eval. If experiment.create_json=True (this is the default in the experiment config) a file named {experiment_name}.json will be created in the experiment output folder with the format of marl-eval. You can load and merge these files using the utils in eval_results to create beautiful plots of your benchmarks. No more struggling with matplotlib and latex!\nConfiguring The project can be configured either the script itself or via hydra. Each component in the project has a corresponding yaml configuration in the BenchMARL conf tree. Components\u0026rsquo; configurations are loaded from these files into python dataclasses that act as schemas for validation of parameter names and types. That way we keep the best of both words: separation of all configuration from code and strong typing for validation! You can also directly load and validate configuration yaml files without using hydra from a script by calling ComponentConfig.get_from_yaml().\nHere are some examples on how you can override configurations:\nExperiments python benchmarl/run.py task=vmas/balance algorithm=mappo experiment.lr=0.03 experiment.evaluation=true experiment.train_device=\u0026quot;cpu\u0026quot; Algorithms python benchmarl/run.py task=vmas/balance algorithm=masac algorithm.num_qvalue_nets=3 algorithm.target_entropy=auto algorithm.share_param_critic=true Tasks Be careful, for benchmarking stability this is not suggested.\npython benchmarl/run.py task=vmas/balance algorithm=mappo task.n_agents=4 Models python benchmarl/run.py task=vmas/balance algorithm=mappo model=sequence \u0026quot;model.intermediate_sizes=[256]\u0026quot; \u0026quot;model/layers@model.layers.l1=mlp\u0026quot; \u0026quot;model/layers@model.layers.l2=mlp\u0026quot; \u0026quot;+model/layers@model.layers.l3=mlp\u0026quot; \u0026quot;model.layers.l3.num_cells=[3]\u0026quot; Check out the section on how to configure BenchMARL and our examples.\nExtending One of the core tenets of BenchMARL is allowing users to leverage the existing algorithm and tasks implementations to benchmark their newly proposed solution.\nFor this reason we expose standard interfaces with simple abstract methods for algorithms, tasks and models. To introduce your solution in the library, you just need to implement the abstract methods exposed by these base classes which use objects from the TorchRL library.\nHere is an example on how you can create a custom algorithm.\nHere is an example on how you can create a custom task.\nHere is an example on how you can create a custom model.\nNext steps BenchMARL is just born and is constantly looking for collaborators to extend and improve its capabilities. If you are interested in joining the project, please reach out!\nThe next steps will include extending the library as well as fine-tuning sets of benchmark hyperparameters to make them available to the community.\nGorsane, Rihab, et al. \u0026ldquo;Towards a standardised performance evaluation protocol for cooperative marl.\u0026rdquo; Advances in Neural Information Processing Systems 35 (2022): 5510-5521.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":1638662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638662400,"objectID":"b5a957e58a8b441b3c27b1225e5d938e","permalink":"https://matteobettini.github.io/post/benchmarl/","publishdate":"2021-12-05T00:00:00Z","relpermalink":"/post/benchmarl/","section":"post","summary":"BenchMARL is a library for benchmarking Multi-Agent Reinforcement Learning (MARL) using TorchRL. BenchMARL allows to quickly compare different MARL algorithms, tasks, and models while being systematically grounded in its two core tenets\u0026#58; reproducibility and standardization.","tags":["Multi-Agent Reinforcement Learning"],"title":"BenchMARL - Benchmarking Multi-Agent Reinforcement Learning","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne **Two** Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://matteobettini.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://matteobettini.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://matteobettini.github.io/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://matteobettini.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]