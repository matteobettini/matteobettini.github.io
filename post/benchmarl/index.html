<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.2.0 for Hugo"><meta name=author content="Matteo Bettini"><meta name=description content="BenchMARL is a library for benchmarking Multi-Agent Reinforcement Learning (MARL) using TorchRL. BenchMARL allows to quickly compare different MARL algorithms, tasks, and models while being systematically grounded in its two core tenets&amp;#58; reproducibility and standardization."><link rel=alternate hreflang=en-us href=https://matteobettini.github.io/post/benchmarl/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#4caf50"><script src=/js/mathjax-config.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.08a6e39f78f6b42de9dcc39ef8155d7d.css><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://matteobettini.github.io/post/benchmarl/><meta property="twitter:card" content="summary_large_image"><meta property="og:site_name" content="Matteo Bettini"><meta property="og:url" content="https://matteobettini.github.io/post/benchmarl/"><meta property="og:title" content="BenchMARL - Benchmarking Multi-Agent Reinforcement Learning | Matteo Bettini"><meta property="og:description" content="BenchMARL is a library for benchmarking Multi-Agent Reinforcement Learning (MARL) using TorchRL. BenchMARL allows to quickly compare different MARL algorithms, tasks, and models while being systematically grounded in its two core tenets&amp;#58; reproducibility and standardization."><meta property="og:image" content="https://matteobettini.github.io/post/benchmarl/featured.png"><meta property="twitter:image" content="https://matteobettini.github.io/post/benchmarl/featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2021-12-05T00:00:00+00:00"><meta property="article:modified_time" content="2021-12-05T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://matteobettini.github.io/post/benchmarl/"},"headline":"BenchMARL - Benchmarking Multi-Agent Reinforcement Learning","image":["https://matteobettini.github.io/post/benchmarl/featured.png"],"datePublished":"2021-12-05T00:00:00Z","dateModified":"2021-12-05T00:00:00Z","author":{"@type":"Person","name":"Matteo Bettini"},"publisher":{"@type":"Organization","name":"Matteo Bettini","logo":{"@type":"ImageObject","url":"https://matteobettini.github.io/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_192x192_fill_lanczos_center_3.png"}},"description":"BenchMARL is a library for benchmarking Multi-Agent Reinforcement Learning (MARL) using TorchRL. BenchMARL allows to quickly compare different MARL algorithms, tasks, and models while being systematically grounded in its two core tenets\u0026#58; reproducibility and standardization."}</script><title>BenchMARL - Benchmarking Multi-Agent Reinforcement Learning | Matteo Bettini</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=b5a957e58a8b441b3c27b1225e5d938e><script src=/js/wowchemy-init.min.4be02a3b391999348b0c7478778a0e4b.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Matteo Bettini</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Matteo Bettini</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#posts><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/#featured><span>Featured</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><article class=article><div class="article-container pt-3"><h1>BenchMARL - Benchmarking Multi-Agent Reinforcement Learning</h1><p class=page-subtitle>BenchMARL is a library for benchmarking Multi-Agent Reinforcement Learning (MARL) using TorchRL. BenchMARL allows to quickly compare different MARL algorithms, tasks, and models while being systematically grounded in its two core tenets: reproducibility and standardization.</p><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span></div><span class=article-date>Dec 5, 2021
</span><span class=middot-divider></span>
<span class=article-reading-time>8 min read</span></div><div class="btn-links mb-3"><a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/post/benchmarl/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header" href=https://github.com/facebookresearch/BenchMARL target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header" href=https://benchmarl.readthedocs.io/ target=_blank rel=noopener>Docs
</a><a class="btn btn-outline-primary btn-page-header" href=https://colab.research.google.com/github/facebookresearch/BenchMARL/blob/main/notebooks/run.ipynb target=_blank rel=noopener>Run in Colab
</a><a class="btn btn-outline-primary btn-page-header" href=https://wandb.ai/matteobettini/benchmarl-public/reportlist target=_blank rel=noopener>Wandb Benchmarks
</a><a class="btn btn-outline-primary btn-page-header" href="https://www.youtube.com/watch?v=1tOIMgJf_VQ" target=_blank rel=noopener>Talk
</a><a class="btn btn-outline-primary btn-page-header" href=https://github.com/facebookresearch/BenchMARL/tree/main/examples target=_blank rel=noopener>Examples</a></div></div><div class="article-header container featured-image-wrapper mt-4 mb-4" style=max-width:1200px;max-height:937px><div style=position:relative><img src=/post/benchmarl/featured_hu0971da7d7467813a850f11c8b39be638_3051643_1200x0_resize_lanczos_3.png alt class=featured-image></div></div><div class=article-container><div class=article-style><p><strong>TL;DR:</strong></p><ul><li>We introduce BenchMARL, a training library for benchmarking MARL algorithms, tasks, and models backed by TorchRL.</li><li>BenchMARL already contains a variety of SOTA algorithms and tasks.</li><li>BenchMARL is grounded by its core tenets: standardization and reproducibility</li></ul><h1 id=what-is-benchmarl->What is BenchMARL üßê?</h1><p>BenchMARL is a Multi-Agent Reinforcement Learning (MARL) training library created to enable reproducibility
and benchmarking across different MARL algorithms and environments.
Its mission is to present a standardized interface that allows easy integration of new algorithms and environments to
provide a fair comparison with existing solutions.
BenchMARL uses <a href=https://github.com/pytorch/rl target=_blank rel=noopener>TorchRL</a> as its backend, which grants it high performance
and state-of-the-art implementations.
It also uses <a href=https://hydra.cc/docs/intro/ target=_blank rel=noopener>hydra</a> for flexible and modular configuration,
and its data reporting is compatible with <a href=https://sites.google.com/view/marl-standard-protocol/home target=_blank rel=noopener>marl-eval</a>
for standardised and statistically strong evaluations.</p><p>BenchMARL <strong>core design tenets</strong> are:</p><ul><li><em>Reproducibility through systematical grounding and standardization of configuration</em></li><li><em>Standardised and statistically-strong plotting and reporting</em></li><li><em>Experiments that are independent of the algorithm, environment, and model choices</em></li><li><em>Breadth over the MARL ecosystem</em></li><li><em>Easy implementation of new algorithms, environments, and models</em></li><li><em>Leveraging the know-how and infrastructure of <a href=https://github.com/pytorch/rl target=_blank rel=noopener>TorchRL</a>, without reinventing the wheel</em></li></ul><h1 id=why-would-i-benchmarl->Why would I BenchMARL ü§î?</h1><p>Why would you BenchMARL, I see you ask.
Well, you can BenchMARL to compare different algorithms, environments, models,
to check how your new research compares to existing ones, or if you just want to approach
the domain and want to easily take a picture of the landscape.</p><h1 id=why-does-it-exist>Why does it exist?</h1><p>We created it because, compared to other ML domains, RL has always been more fragmented
in terms of shared community standards, tools, and interfaces.
In MARL, this problem is even more evident, with new libraries being frequently
introduced that focus on specific algorithms, environments, or models. Furthermore,
these libraries often implement components from scratch, without leveraging the know-how of
the single-agent RL community. In fact, the great majority of components used in MARL is shared
with single-agent RL (e.g., losses like MAPPO, models, probability distributions, replay buffers, and much more).</p><p>This fragmentation of the domain has led to a reproducibility crisis, recently highlighted in
a NeurIPS paper <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. While authors in <sup id=fnref1:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> propose a set of tools for statistically-strong results&rsquo; reporting,
there is still the need for a standardized library to run such benchmarks.
This is where BenchMARL comes in. Its mission is to provide a benchmarking tool for MARL,
leveraging the components of TorchRL for a solid RL backend.</p><h1 id=how-do-i-use-it>How do I use it?</h1><h3 id=command-line>Command line</h3><p>Simple, to run an experiment from the command line do:</p><pre><code class=language-bash>python benchmarl/run.py algorithm=mappo task=vmas/balance
</code></pre><p>to run multiple experiments, a benchmark you can do:</p><pre><code class=language-bash>python benchmarl/run.py -m algorithm=mappo,qmix,masac task=vmas/balance,vmas/sampling seed=0,1
</code></pre><p>Multirun has many launchers supported in the backend.
The default implementation for hydra multirun is sequential, but <a href=https://hydra.cc/docs/plugins/joblib_launcher/ target=_blank rel=noopener>parallel</a> and
<a href=https://hydra.cc/docs/plugins/submitit_launcher/ target=_blank rel=noopener>slurm</a> launchers are also available.</p><h3 id=script>Script</h3><p>Run an experiment:</p><pre><code class=language-python>experiment = Experiment(
    task=VmasTask.BALANCE.get_from_yaml(),
    algorithm_config=MappoConfig.get_from_yaml(),
    model_config=MlpConfig.get_from_yaml(),
    critic_model_config=MlpConfig.get_from_yaml(),
    seed=0,
    config=ExperimentConfig.get_from_yaml(),
)
experiment.run()
</code></pre><p>Run a benchmark:</p><pre><code class=language-python>benchmark = Benchmark(
    algorithm_configs=[
        MappoConfig.get_from_yaml(),
        QmixConfig.get_from_yaml(),
        MasacConfig.get_from_yaml(),
    ],
    tasks=[
        VmasTask.BALANCE.get_from_yaml(),
        VmasTask.SAMPLING.get_from_yaml(),
    ],
    seeds={0, 1},
    experiment_config=ExperimentConfig.get_from_yaml(),
    model_config=MlpConfig.get_from_yaml(),
    critic_model_config=MlpConfig.get_from_yaml(),
)
benchmark.run_sequential()
</code></pre><h1 id=components>Components</h1><p>The goal of BenchMARL is to bring different MARL environments and algorithms
under the same interfaces to enable fair and reproducible comparison and benchmarking.
BenchMARL is a full-pipline unified training library with the goal of enabling users to run
any comparison they want across our algorithms and tasks in just one line of code.
To achieve this, BenchMARL interconnects components from <a href=https://github.com/pytorch/rl target=_blank rel=noopener>TorchRL</a>,
which provides an efficient and reliable backend.</p><p>The library has a <a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf target=_blank rel=noopener>default configuration</a> for each of its components.
While parts of this configuration are supposed to be changed (for example experiment configurations),
other parts (such as tasks) should not be changed to allow for reproducibility.
To aid in this, each version of BenchMARL is paired to a default configuration.</p><p>Let&rsquo;s now introduce each component in the library.</p><p><strong>Experiment</strong>. An experiment is a training run in which an algorithm, a task, and a model are fixed.
Experiments are configured by passing these values alongside a seed and the experiment hyperparameters.
The experiment <a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf/experiment/base_experiment.yaml target=_blank rel=noopener>hyperparameters</a> cover both
on-policy and off-policy algorithms, discrete and continuous actions, and probabilistic and deterministic policies
(as they are agnostic of the algorithm or task used).
An experiment can be launched from the command line or from a script.</p><p><strong>Benchmark</strong>. In the library we call <code>benchmark</code> a collection of experiments that can vary in tasks, algorithm, or model.
A benchmark shares the same experiment configuration across all of its experiments.
Benchmarks allow to compare different MARL components in a standardized way.
A benchmark can be launched from the command line or from a script.</p><p><strong>Algorithms</strong>. Algorithms are an ensemble of components (e.g., losss, replay buffer) which
determine the training strategy. Here is a table with the currently implemented algorithms in BenchMARL.</p><table><thead><tr><th>Name</th><th>On/Off policy</th><th>Actor-critic</th><th>Full-observability in critic</th><th>Action compatibility</th><th>Probabilistic actor</th></tr></thead><tbody><tr><td><a href=https://arxiv.org/abs/2103.01955 target=_blank rel=noopener>MAPPO</a></td><td>On</td><td>Yes</td><td>Yes</td><td>Continuous + Discrete</td><td>Yes</td></tr><tr><td><a href=https://arxiv.org/abs/2011.09533 target=_blank rel=noopener>IPPO</a></td><td>On</td><td>Yes</td><td>No</td><td>Continuous + Discrete</td><td>Yes</td></tr><tr><td><a href=https://arxiv.org/abs/1706.02275 target=_blank rel=noopener>MADDPG</a></td><td>Off</td><td>Yes</td><td>Yes</td><td>Continuous</td><td>No</td></tr><tr><td><a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/algorithms/iddpg.py target=_blank rel=noopener>IDDPG</a></td><td>Off</td><td>Yes</td><td>No</td><td>Continuous</td><td>No</td></tr><tr><td><a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/algorithms/masac.py target=_blank rel=noopener>MASAC</a></td><td>Off</td><td>Yes</td><td>Yes</td><td>Continuous + Discrete</td><td>Yes</td></tr><tr><td><a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/algorithms/isac.py target=_blank rel=noopener>ISAC</a></td><td>Off</td><td>Yes</td><td>No</td><td>Continuous + Discrete</td><td>Yes</td></tr><tr><td><a href=https://arxiv.org/abs/1803.11485 target=_blank rel=noopener>QMIX</a></td><td>Off</td><td>No</td><td>NA</td><td>Discrete</td><td>No</td></tr><tr><td><a href=https://arxiv.org/abs/1706.05296 target=_blank rel=noopener>VDN</a></td><td>Off</td><td>No</td><td>NA</td><td>Discrete</td><td>No</td></tr><tr><td><a href=https://www.semanticscholar.org/paper/Multi-Agent-Reinforcement-Learning%3A-Independent-Tan/59de874c1e547399b695337bcff23070664fa66e target=_blank rel=noopener>IQL</a></td><td>Off</td><td>No</td><td>NA</td><td>Discrete</td><td>No</td></tr></tbody></table><p><strong>Tasks</strong>. Tasks are scenarios from a specific environment which constitute the MARL
challenge to solve.
They differ based on many aspects, here is a table with the current environments in BenchMARL</p><table><thead><tr><th>Environment</th><th>Tasks</th><th>Cooperation</th><th>Global state</th><th>Reward function</th><th>Action space</th><th style=text-align:center>Vectorized</th></tr></thead><tbody><tr><td><a href=https://github.com/proroklab/VectorizedMultiAgentSimulator target=_blank rel=noopener>VMAS</a></td><td><a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf/task/vmas target=_blank rel=noopener>5</a></td><td>Cooperative + Competitive</td><td>No</td><td>Shared + Independent + Global</td><td>Continuous + Discrete</td><td style=text-align:center>Yes</td></tr><tr><td><a href=https://github.com/oxwhirl/smacv2 target=_blank rel=noopener>SMACv2</a></td><td><a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf/task/smacv2 target=_blank rel=noopener>15</a></td><td>Cooperative</td><td>Yes</td><td>Global</td><td>Discrete</td><td style=text-align:center>No</td></tr><tr><td><a href=https://github.com/openai/multiagent-particle-envs target=_blank rel=noopener>MPE</a></td><td><a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf/task/pettingzoo target=_blank rel=noopener>8</a></td><td>Cooperative + Competitive</td><td>Yes</td><td>Shared + Independent</td><td>Continuous + Discrete</td><td style=text-align:center>No</td></tr><tr><td><a href=https://github.com/sisl/MADRL target=_blank rel=noopener>SISL</a></td><td><a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf/task/pettingzoo target=_blank rel=noopener>2</a></td><td>Cooperative</td><td>No</td><td>Shared</td><td>Continuous</td><td style=text-align:center>No</td></tr></tbody></table><blockquote><p>BenchMARL uses the <a href=https://github.com/pytorch/rl/issues/1463 target=_blank rel=noopener>TorchRL MARL API</a> for grouping agents.
In competitive environments like MPE, for example, teams will be in different groups. Each group has its own loss,
models, buffers, and so on. Parameter sharing options refer to sharing within the group. See the example on <a href=https://github.com/facebookresearch/BenchMARL/tree/main/examples/extending/algorithm/custom_algorithm.py target=_blank rel=noopener>creating
a custom algorithm</a> for more info.</p></blockquote><p><strong>Models</strong>. Models are neural networks used to process data. They can be used as actors (policies) or,
when requested, as critics. We provide a set of base models (layers) and a SequenceModel to concatenate
different layers. All the models can be used with or without parameter sharing within an
agent group. Here is a table of the models implemented in BenchMARL</p><table><thead><tr><th>Name</th><th style=text-align:center>Decentralized</th><th style=text-align:center>Centralized with local inputs</th><th style=text-align:center>Centralized with global input</th></tr></thead><tbody><tr><td><a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/models/mlp.py target=_blank rel=noopener>MLP</a></td><td style=text-align:center>Yes</td><td style=text-align:center>Yes</td><td style=text-align:center>Yes</td></tr></tbody></table><p>And the ones that are <em>work in progress</em></p><table><thead><tr><th>Name</th><th style=text-align:center>Decentralized</th><th style=text-align:center>Centralized with local inputs</th><th style=text-align:center>Centralized with global input</th></tr></thead><tbody><tr><td>GNN</td><td style=text-align:center>Yes</td><td style=text-align:center>Yes</td><td style=text-align:center>No</td></tr><tr><td>CNN</td><td style=text-align:center>Yes</td><td style=text-align:center>Yes</td><td style=text-align:center>Yes</td></tr></tbody></table><h1 id=features>Features</h1><p>BenchMARL has many features. In this section we will dive deep
in the features that correspond to our core design tenets, but there are many more cool
nuggets here and there, such as:</p><ul><li><strong>A test CI</strong> with integration and training test routines that are run <strong>for all simulators and algorithms</strong></li><li>Integration in the <strong>official TorchRL ecosystem</strong> for dedicated support</li><li>Experiment <strong>checkpointing</strong> and restoring using <code>torch</code></li><li>Experiment <strong>logging</strong> compatible with many loggers (wandb, csv, mflow, tensorboard).
The wandb logger is fully compatible with experiment restoring and will automatically resume the run of the loaded experiment.</li></ul><p>In the following we illustrate the features which are core to our tenets.</p><h2 id=fine-tuned-public-benchmarks>Fine-tuned public benchmarks</h2><p>In the <a href=https://github.com/facebookresearch/BenchMARL/blob/main/fine_tuned target=_blank rel=noopener>fine_tuned</a> folder
we are collecting some tested hyperparameters for
specific environments to enable users to bootstrap their benchmarking.
You can just run the scripts in this folder to automatically use the proposed hyperparameters.</p><p>We will tune benchmarks for you and publish the config and benchmarking plots on
<a href=https://wandb.ai/matteobettini/benchmarl-public/reportlist target=_blank rel=noopener>Wandb</a> publicly</p><p>Currently available ones are:</p><div class=row><b>VVMAS:</b>
<a href=https://github.com/facebookresearch/BenchMARL/blob/main/fine_tuned/vmas/conf/config.yaml><img src=https://img.shields.io/badge/Conf-purple.svg>
</a><a href=https://api.wandb.ai/links/matteobettini/r5744vas><img src=https://img.shields.io/badge/Benchmarks-Wandb-yellow></a></div><p>In the following, we report a table of the results:</p><table><thead><tr><th><strong><p align=center>Environment</p></strong></th><th><strong><p align=center>Sample efficiency curves (all tasks)</p></strong></th><th><strong><p align=center>Performance profile</p></strong></th><th><strong><p align=center>Aggregate scores</p></strong></th></tr></thead><tbody><tr><td>VMAS</td><td><img src="https://drive.google.com/uc?export=view&id=1fzfFn0q54gsALRAwmqD1hRTqQIadGPoE"></td><td><img src="https://drive.google.com/uc?export=view&id=151pSR2sBluSpWiYxtq3jNX0tfE0vgAuR"></td><td><img src="https://drive.google.com/uc?export=view&id=1q2So9V6sL8NHMtj6vL-S3KyzZi11Vfia"></td></tr></tbody></table><h2 id=reporting-and-plotting>Reporting and plotting</h2><p>Reporting and plotting is compatible with <a href=https://github.com/instadeepai/marl-eval target=_blank rel=noopener>marl-eval</a>.
If <code>experiment.create_json=True</code> (this is the default in the <a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf/experiment/base_experiment.yaml target=_blank rel=noopener>experiment config</a>)
a file named <code>{experiment_name}.json</code> will be created in the experiment output folder with the format of <a href=https://github.com/instadeepai/marl-eval target=_blank rel=noopener>marl-eval</a>.
You can load and merge these files using the utils in <a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/eval_results.py target=_blank rel=noopener>eval_results</a> to create beautiful plots of
your benchmarks. No more struggling with matplotlib and latex!</p><p><img src="https://drive.google.com/uc?export=view&amp;id=1q2So9V6sL8NHMtj6vL-S3KyzZi11Vfia" alt=aggregate_scores>
<img src="https://drive.google.com/uc?export=view&amp;id=1fzfFn0q54gsALRAwmqD1hRTqQIadGPoE" alt=sample_efficiancy>
<img src="https://drive.google.com/uc?export=view&amp;id=151pSR2sBluSpWiYxtq3jNX0tfE0vgAuR" alt=performace_profile></p><h2 id=configuring>Configuring</h2><p>The project can be configured either the script itself or via <a href=https://hydra.cc/docs/intro/ target=_blank rel=noopener>hydra</a>.
Each component in the project has a corresponding yaml configuration in the BenchMARL
<a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/conf target=_blank rel=noopener>conf</a> tree.
Components&rsquo; configurations are loaded from these files into python dataclasses that act as schemas for
validation of parameter names and types. That way we keep the best of both words: separation of all
configuration from code and strong typing for validation! You can also directly load and validate
configuration yaml files without using hydra from a script by calling <code>ComponentConfig.get_from_yaml()</code>.</p><p>Here are some examples on how you can override configurations:</p><h4 id=experiments>Experiments</h4><pre><code class=language-bash>python benchmarl/run.py task=vmas/balance algorithm=mappo experiment.lr=0.03 experiment.evaluation=true experiment.train_device=&quot;cpu&quot;
</code></pre><h4 id=algorithms>Algorithms</h4><pre><code class=language-bash>python benchmarl/run.py task=vmas/balance algorithm=masac algorithm.num_qvalue_nets=3 algorithm.target_entropy=auto algorithm.share_param_critic=true
</code></pre><h4 id=tasks>Tasks</h4><p>Be careful, for benchmarking stability this is not suggested.</p><pre><code class=language-bash>python benchmarl/run.py task=vmas/balance algorithm=mappo task.n_agents=4
</code></pre><h4 id=models>Models</h4><pre><code class=language-bash>python benchmarl/run.py task=vmas/balance algorithm=mappo model=sequence &quot;model.intermediate_sizes=[256]&quot; &quot;model/layers@model.layers.l1=mlp&quot; &quot;model/layers@model.layers.l2=mlp&quot; &quot;+model/layers@model.layers.l3=mlp&quot; &quot;model.layers.l3.num_cells=[3]&quot;
</code></pre><p>Check out the <a href=https://github.com/facebookresearch/BenchMARL#configuring target=_blank rel=noopener>section on how to configure BenchMARL</a> and
our <a href=https://github.com/facebookresearch/BenchMARL/tree/main/examples/configuring target=_blank rel=noopener>examples</a>.</p><h2 id=extending>Extending</h2><p>One of the core tenets of BenchMARL is allowing users to leverage the existing algorithm
and tasks implementations to benchmark their newly proposed solution.</p><p>For this reason we expose standard interfaces with simple abstract methods
for <a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/algorithms/common.py target=_blank rel=noopener>algorithms</a>,
<a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/environments/common.py target=_blank rel=noopener>tasks</a> and
<a href=https://github.com/facebookresearch/BenchMARL/tree/main/benchmarl/models/common.py target=_blank rel=noopener>models</a>.
To introduce your solution in the library, you just need to implement the abstract methods
exposed by these base classes which use objects from the <a href=https://github.com/pytorch/rl target=_blank rel=noopener>TorchRL</a> library.</p><p>Here is an <a href=https://github.com/facebookresearch/BenchMARL/tree/main/examples/extending/algorithm target=_blank rel=noopener>example on how you can create a custom algorithm</a>.</p><p>Here is an <a href=https://github.com/facebookresearch/BenchMARL/tree/main/examples/extending/task target=_blank rel=noopener>example on how you can create a custom task</a>.</p><p>Here is an <a href=https://github.com/facebookresearch/BenchMARL/tree/main/examples/extending/model target=_blank rel=noopener>example on how you can create a custom model</a>.</p><h1 id=next-steps>Next steps</h1><p>BenchMARL is just born and is constantly looking for collaborators to extend and improve its capabilities.
<strong>If you are interested in joining the project, please reach out!</strong></p><p>The next steps will include extending the library as well as fine-tuning sets of benchmark hyperparameters
to make them available to the community.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><em>Gorsane, Rihab, et al. &ldquo;Towards a standardised performance evaluation protocol
for cooperative marl.&rdquo; Advances in Neural Information Processing Systems 35 (2022): 5510-5521.</em>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=article-tags><a class="badge badge-light" href=/tag/multi-agent-reinforcement-learning/>Multi-Agent Reinforcement Learning</a></div><div class="media author-card content-widget-hr"><a href=https://matteobettini.github.io/><img class="avatar mr-3 avatar-circle" src=/authors/admin/avatar_hud6e8b1feea32bacba9d9483ffbfda6ff_281920_270x270_fill_q100_lanczos_center.JPG alt="Matteo Bettini"></a><div class=media-body><h5 class=card-title><a href=https://matteobettini.github.io/>Matteo Bettini</a></h5><h6 class=card-subtitle>PhD Candidate</h6><p class=card-text>Matteo&rsquo;s research is focused on studying heterogeneity and resilience in multi-agent and multi-robot systems.</p><ul class=network-icon aria-hidden=true><li><a href=/#contact><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?user=hcvR_W0AAAAJ" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://github.com/matteobettini target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://linkedin.com/in/bettinimatteo target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=/uploads/Matteo%20bettini%20-%20CV.pdf><i class="ai ai-cv"></i></a></li></ul></div></div><div class="article-widget content-widget-hr"><h3>Related</h3><ul><li><a href=/publication/benchmarl/>BenchMARL: Benchmarking Multi-Agent Reinforcement Learning</a></li><li><a href=/publication/heterogeneous-multi-robot-reinforcement-learning/>Heterogeneous Multi-Robot Reinforcement Learning</a></li><li><a href=/publication/system-neural-diversity-measuring-behavioral-heterogeneity-in-multi-agent-learning/>System Neural Diversity: Measuring Behavioral Heterogeneity in Multi-Agent Learning</a></li><li><a href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/>TorchRL: A data-driven decision-making library for PyTorch</a></li><li><a href=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/>VMAS: A Vectorized Multi-Agent Simulator for Collective Robot Learning</a></li></ul></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>View <a href=https://github.com/matteobettini/professional_website target=_blank rel=noopener>source</a>.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script><script src=/en/js/wowchemy.min.f7a5e0a5c39e010ad2fd6899a284771d.js></script><script async defer src=https://buttons.github.io/buttons.js></script></body></html>