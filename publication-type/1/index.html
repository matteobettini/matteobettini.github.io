<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.2.0 for Hugo"><meta name=author content="Matteo Bettini"><meta name=description content="PhD Candidate"><link rel=alternate hreflang=en-us href=https://matteobettini.github.io/publication-type/1/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#4caf50"><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.08a6e39f78f6b42de9dcc39ef8155d7d.css><link rel=alternate href=/publication-type/1/index.xml type=application/rss+xml title="Matteo Bettini"><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://matteobettini.github.io/publication-type/1/><meta property="twitter:card" content="summary"><meta property="og:site_name" content="Matteo Bettini"><meta property="og:url" content="https://matteobettini.github.io/publication-type/1/"><meta property="og:title" content="1 | Matteo Bettini"><meta property="og:description" content="PhD Candidate"><meta property="og:image" content="https://matteobettini.github.io/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://matteobettini.github.io/media/icon_hueab793ca17b85ea7e4569d22d387be97_25680_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2024-05-29T00:00:00+00:00"><title>1 | Matteo Bettini</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper><script src=/js/wowchemy-init.min.4be02a3b391999348b0c7478778a0e4b.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Matteo Bettini</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Matteo Bettini</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#featured><span>Featured</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><div class="universal-wrapper pt-3"><h1>1</h1></div><div class=universal-wrapper><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/>Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning</a></div><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/ class=summary-link><div class=article-style>We introduce Diversity Control (DiCo), a method able to control diversity to an exact value of a given metric by representing policies as the sum of a parameter-shared component and dynamically scaled per-agent components. By applying constraints directly to the policy architecture, DiCo leaves the learning objective unchanged, enabling its applicability to any actor-critic MARL algorithm. We theoretically prove that DiCo achieves the desired diversity, and we provide several experiments, both in cooperative and competitive tasks, that show how DiCo can be employed as a novel paradigm to increase performance and sample efficiency in MARL.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/kortvelesy/>Ryan Kortvelesy</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>International Conference on Machine Learning (ICML)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/Controlling-Behavioral-Diversity-in-Multi-Agent-Reinforcement-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/ControllingBehavioralDiversity target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://sites.google.com/view/dico-marl target=_blank rel=noopener>Website</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=qQjUgItPq4" target=_blank rel=noopener>OpenReview</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2405.15054 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/poster.pdf>Poster</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/><img src=/publication/controlling-behavioral-diversity-in-multi-agent-reinforcement-learning/compact_hu9dca1e83ecb59c40dcc79a7f11d4d205_4216083_300x0_resize_lanczos.gif alt="Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning" loading=lazy></a></div></div></div><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/robomaster/>The Cambridge RoboMaster: An Agile Multi-Robot Research Platform</a></div><a href=/publication/robomaster/ class=summary-link><div class=article-style>This article introduces a tightly integrated hardware, control, and simulation software stack on a fleet of holonomic ground robot platforms. Our robots, a fleet of customised DJI Robomaster S1 vehicles, offer a balance between small robots that do not possess sufficient compute or actuation capabilities and larger robots that are unsuitable for indoor multi-robot tests.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/authors/blumenkamp/>Jan Blumenkamp</a></span>, <span><a href=/authors/shankar/>Ajay Shankar</a></span>, <span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/joshua-bird/>Joshua Bird</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Distributed Autonomous Robotic Systems (DARS)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/robomaster/robomaster.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/robomaster/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/cambridge-robomaster target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://proroklab.github.io/cambridge-robomaster/supplementary.html#vmas-deployment target=_blank rel=noopener>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://proroklab.github.io/cambridge-robomaster/ target=_blank rel=noopener>Docs</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2405.02198 target=_blank rel=noopener>arXiv</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/robomaster/><img src=/publication/robomaster/compact_hu46efff4e28ca506a88be1427516cbd21_2261186_300x0_resize_lanczos_3.png alt="The Cambridge RoboMaster: An Agile Multi-Robot Research Platform" loading=lazy></a></div></div></div><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/>TorchRL: A data-driven decision-making library for PyTorch</a></div><a href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/ class=summary-link><div class=article-style>We propose TorchRL, a generalistic control library for PyTorch that provides well-integrated, yet standalone components. With a versatile and robust primitive design, TorchRL facilitates streamlined algorithm development across the many branches of Reinforcement Learning (RL) and control. We introduce a new PyTorch primitive, TensorDict, as a flexible data carrier that empowers the integration of the library’s components while preserving their modularity. TorchRL fosters long-term support and is publicly available on GitHub for greater reproducibility and collaboration within the research community.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/authors/albert-bou/>Albert Bou</a></span>, <span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/sebastian-dittert/>Sebastian Dittert</a></span>, <span><a href=/authors/vikash-kumar/>Vikash Kumar</a></span>, <span><a href=/authors/shagun-sodhani/>Shagun Sodhani</a></span>, <span><a href=/authors/xiaomeng-yang/>Xiaomeng Yang</a></span>, <span><a href=/authors/gianni-de-fabritiis/>Gianni De Fabritiis</a></span>, <span><a href=/authors/vincent-moens/>Vincent Moens</a></span></div><span class=article-date>2024</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>International Conference on Learning Representations (ICLR)</em> - <strong><em>Spotlight (top 5%)</em></strong></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/TorchRL-A-data-driven-decision-making-library-for-PyTorch.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/pytorch/rl target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://pytorch.org/rl/ target=_blank rel=noopener>Documentation</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2306.00577 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=QxItoEAVMb" target=_blank rel=noopener>OpenReview</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/poster.pdf>Poster</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/><img src=/publication/torchrl-a-data-driven-decision-making-library-for-pytorch/compact_hu903fd55680461821a9b538ed6f8cf6de_77481_300x0_resize_lanczos_3.png alt="TorchRL: A data-driven decision-making library for PyTorch" loading=lazy></a></div></div></div><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/heterogeneous-multi-robot-reinforcement-learning/>Heterogeneous Multi-Robot Reinforcement Learning</a></div><a href=/publication/heterogeneous-multi-robot-reinforcement-learning/ class=summary-link><div class=article-style>In this paper, we crystallize the role of heterogeneity in MARL policies. We introduce Heterogeneous Graph Neural Network Proximal Policy Optimization (HetGPPO), a paradigm for training heterogeneous MARL policies that leverages a Graph Neural Network for differentiable inter-agent communication. HetGPPO allows communicating agents to learn heterogeneous behaviors while enabling fully decentralized training in partially observable environments. Through simulations and real-world experiments, we show that: (i) when homogeneous methods fail due to strong heterogeneous requirements, HetGPPO succeeds, and, (ii) when homogeneous methods are able to learn apparently heterogeneous behaviors, HetGPPO achieves higher resilience to both training and deployment noise.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/shankar/>Ajay Shankar</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2023</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Autonomous Agents and Multiagent Systems (AAMAS)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/heterogeneous-multi-robot-reinforcement-learning/Heterogeneous-Multi-Robot-Reinforcement-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/heterogeneous-multi-robot-reinforcement-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/HetGPPO target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=J81IVQEy-zw" target=_blank rel=noopener>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2301.07137 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=a4md0es3kuo" target=_blank rel=noopener>Talk</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/heterogeneous-multi-robot-reinforcement-learning/poster.pdf>Poster</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/heterogeneous-multi-robot-reinforcement-learning/><img src=/publication/heterogeneous-multi-robot-reinforcement-learning/compact_hu1234d6e5d8e0fe29abec561068287070_2300259_300x0_resize_lanczos_3.png alt="Heterogeneous Multi-Robot Reinforcement Learning" loading=lazy></a></div></div></div><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/>POPGym: Benchmarking Partially Observable Reinforcement Learning</a></div><a href=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/ class=summary-link><div class=article-style>We introduce Partially Observable Process Gym (POPGym), a two-part library containing (1) a diverse collection of 14 partially observable environments, each with multiple difficulties and (2) implementations of 13 memory model baselines – the most in a single RL library. Using POPGym, we execute the largest comparison across RL memory models to date.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/authors/morad/>Steven Morad</a></span>, <span><a href=/authors/kortvelesy/>Ryan Kortvelesy</a></span>, <span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/stephan-liwicki/>Stephan Liwicki</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2023</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>International Conference on Learning Representations (ICLR)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/POPGym-Benchmarking-Partially-Observable-Reinforcement-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/smorad/popgym target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2303.01859 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=chDrutUTs0K" target=_blank rel=noopener>OpenReview</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/><img src=/publication/popgym-benchmarking-partially-observable-reinforcement-learning/compact_hu08087b80d13a316aaceae06d8ed23885_323361_300x0_resize_lanczos_3.png alt="POPGym: Benchmarking Partially Observable Reinforcement Learning" loading=lazy></a></div></div></div><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/>VMAS: A Vectorized Multi-Agent Simulator for Collective Robot Learning</a></div><a href=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/ class=summary-link><div class=article-style>In this paper, we introduce the Vectorized Multi-Agent Simulator (VMAS). VMAS is an open-source framework designed for efficient MARL benchmarking. It comprises a vectorized 2D physics engine written in PyTorch and a set of twelve challenging multi-robot scenarios. Additional scenarios can be implemented through a simple and modular interface. We demonstrate how vectorization enables parallel simulation on accelerated hardware without added complexity.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/kortvelesy/>Ryan Kortvelesy</a></span>, <span><a href=/authors/blumenkamp/>Jan Blumenkamp</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2022</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>Distributed Autonomous Robotic Systems (DARS)</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/VMAS-A-Vectorized-Multi-Agent-Simulator-for-Collective-Robot-Learning.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/proroklab/VectorizedMultiAgentSimulator target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=aaDRYfiesAY&t=1s" target=_blank rel=noopener>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2207.03530 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/boViBY7Woqg target=_blank rel=noopener>Talk</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/><img src=/publication/vmas-a-vectorized-multi-agent-simulator-for-collective-robot-learning/compact_hua4f5b9e0add8e9e8c3203a579e61fbd6_755644_300x0_resize_lanczos_3.png alt="VMAS: A Vectorized Multi-Agent Simulator for Collective Robot Learning" loading=lazy></a></div></div></div><div class=container><div class="row media stream-item"><div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body"><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/on-the-properties-of-path-additions-for-traffic-routing/>On the Properties of Path Additions for Traffic Routing</a></div><a href=/publication/on-the-properties-of-path-additions-for-traffic-routing/ class=summary-link><div class=article-style>In this paper, we investigate the impact of path additions to transport networks with optimised traffic routing. In particular, we study the behaviour of total travel time, and consider both self-interested routing paradigms, such as User Equilibrium (UE) routing, as well as cooperative paradigms, such as classic Multi-Commodity (MC) network flow and System Optimal (SO) routing. This work aims to provide an analysis and categorization of the properties of objective functions for transport network design, with the purpose of informing algorithm (and also network) designers. Among our results, we prove, via counterexample, that total travel time, under both cooperative and self-interested routing, is not supermodular with respect to path additions.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted><a href=/authors/admin/>Matteo Bettini</a></span>, <span><a href=/authors/prorok/>Amanda Prorok</a></span></div><span class=article-date>2022</span>
<span class=middot-divider></span>
<span class=pub-publication>In <em>IEEE International Conference on Intelligent Transportation Systems (ITSC) Workshop on Co-Design and Coordination of Future Mobility Systems</em></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/on-the-properties-of-path-additions-for-traffic-routing/On-the-properties-of-path-additions-for-traffic-routing.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/on-the-properties-of-path-additions-for-traffic-routing/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/matteobettini/Traffic-Assignment-Frank-Wolfe-2021 target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2207.04505 target=_blank rel=noopener>arXiv</a></div></div><div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3"><a href=/publication/on-the-properties-of-path-additions-for-traffic-routing/><img src=/publication/on-the-properties-of-path-additions-for-traffic-routing/compact_hub80e700c5eadfc1ac79e44fc5dc02fe5_506162_300x0_resize_lanczos_3.png alt="On the Properties of Path Additions for Traffic Routing" loading=lazy></a></div></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>View <a href=https://github.com/matteobettini/professional_website target=_blank rel=noopener>source</a>.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script>
<script src=/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script>
<script src=/en/js/wowchemy.min.26bc5a5b73c468c9e767656a378ac5e3.js></script>
<script async defer src=https://buttons.github.io/buttons.js></script></body></html>